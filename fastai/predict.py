from fastai.vision.all import *
import pandas as pd
import numpy as np
import os
import torch
import argparse
from pathlib import Path
import json
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm
import time
import sys

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å‹å’Œå·¥å…·æ¨¡å—
sys.path.insert(0, str(Path(__file__).parent))
try:
    from models import get_model, is_custom_model
    from utils import dice_score, DiceMetric
    CUSTOM_MODELS_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸  è‡ªå®šä¹‰æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    CUSTOM_MODELS_AVAILABLE = False
    is_custom_model = lambda x: False

def detect_dataset_structure(data_dir):
    """æ£€æµ‹æ•°æ®é›†çš„ç»„ç»‡ç»“æ„ï¼Œæ”¯æŒä¸åŒçš„ç›®å½•ç»“æ„æ¨¡å¼
    
    æ”¯æŒçš„ç»“æ„:
    1. data_dir/train/class1, data_dir/train/class2, ...
    2. data_dir/val/class1, data_dir/val/class2, ...
    3. data_dir/class1/train, data_dir/class2/train, ...
    4. data_dir/class1/val, data_dir/class2/val, ...
    
    Returns:
        tuple: (structure_type, classes)
        structure_type: 1 = æ•°æ®é›†æŒ‰å­é›†åˆ†ç»„, 2 = æ•°æ®é›†æŒ‰ç±»åˆ«åˆ†ç»„
        classes: ç±»åˆ«åˆ—è¡¨
    """
    data_dir = Path(data_dir)
    
    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨train/valå­ç›®å½•ï¼Œç»“æ„ç±»å‹1
    train_dir = data_dir / "train"
    val_dir = data_dir / "val"
    
    if val_dir.exists() and val_dir.is_dir():
        # æ£€æŸ¥valç›®å½•ä¸‹æ˜¯å¦æœ‰ç±»åˆ«å­ç›®å½•
        class_dirs = [d for d in val_dir.iterdir() if d.is_dir()]
        if class_dirs:
            classes = [d.name for d in class_dirs]
            print(f"æ£€æµ‹åˆ°æ•°æ®é›†ç»“æ„: data_dir/val/class, ç±»åˆ«: {classes}")
            return 1, classes
    
    if train_dir.exists() and train_dir.is_dir():
        # æ£€æŸ¥trainç›®å½•ä¸‹æ˜¯å¦æœ‰ç±»åˆ«å­ç›®å½•
        class_dirs = [d for d in train_dir.iterdir() if d.is_dir()]
        if class_dirs:
            classes = [d.name for d in class_dirs]
            print(f"æ£€æµ‹åˆ°æ•°æ®é›†ç»“æ„: data_dir/train/class, ç±»åˆ«: {classes}")
            return 1, classes
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ç±»åˆ«ç›®å½•ï¼Œæ¯ä¸ªç±»åˆ«ç›®å½•ä¸‹æœ‰train/valï¼Œç»“æ„ç±»å‹2
    subdirs = [d for d in data_dir.iterdir() if d.is_dir()]
    for subdir in subdirs:
        train_subdir = subdir / "train"
        val_subdir = subdir / "val"
        if (train_subdir.exists() and train_subdir.is_dir()) or \
           (val_subdir.exists() and val_subdir.is_dir()):
            classes = [d.name for d in subdirs]
            print(f"æ£€æµ‹åˆ°æ•°æ®é›†ç»“æ„: data_dir/class/train|val, ç±»åˆ«: {classes}")
            return 2, classes
    
    # å°è¯•ç¬¬ä¸‰ç§ç»“æ„ï¼Œæ£€æŸ¥ä¸€çº§å­ç›®å½•ä¸‹çš„äºŒçº§å­ç›®å½•
    all_subdirs = []
    for subdir in subdirs:
        sub_subdirs = [d for d in subdir.iterdir() if d.is_dir()]
        all_subdirs.extend(sub_subdirs)
    
    # ä»æ‰€æœ‰äºŒçº§å­ç›®å½•æ”¶é›†æ½œåœ¨çš„ç±»åˆ«
    if all_subdirs:
        potential_classes = set()
        for d in all_subdirs:
            potential_class = d.parent.name
            if potential_class not in ['train', 'val', 'test']:
                potential_classes.add(potential_class)
        
        if potential_classes:
            classes = list(potential_classes)
            print(f"æ£€æµ‹åˆ°å¯èƒ½çš„ç±»åˆ«: {classes}")
            return 3, classes
    
    # æ‰¾ä¸åˆ°æ¸…æ™°çš„ç»“æ„
    print("æ— æ³•è‡ªåŠ¨æ£€æµ‹æ•°æ®é›†ç»“æ„")
    return 0, []

def build_test_df(root_dir, subset="val"):
    """æ„å»ºæµ‹è¯•æ•°æ®é›†çš„DataFrame"""
    path = Path(root_dir).absolute()
    records = []
    
    # æ£€æµ‹æ•°æ®é›†ç»“æ„
    structure_type, classes = detect_dataset_structure(path)
    
    if structure_type == 1:
        # æ•°æ®é›†æŒ‰å­é›†åˆ†ç»„: data_dir/train/class, data_dir/val/class
        base_path = path / subset
        
        if base_path.exists():
            print(f"ä½¿ç”¨ç›®å½• {base_path} ä¸­çš„å›¾åƒè¿›è¡Œè¯„ä¼°")
            for img_path in base_path.rglob("*.*"):
                if img_path.is_file() and img_path.suffix.lower() in ['.jpg', '.png', '.jpeg', '.bmp']:
                    rel_path = img_path.relative_to(path)
                    # ç¡®ä¿ä»valç›®å½•çš„ç›´æ¥å­ç›®å½•è·å–ç±»åˆ«åç§°
                    parts = rel_path.parts
                    if len(parts) >= 2 and parts[0] == subset:
                        class_label = parts[1]  # val/<class_name>/...
                    else:
                        class_label = img_path.parent.name
                    
                    records.append({
                        "filename": str(rel_path),
                        "label": class_label
                    })
        else:
            print(f"è­¦å‘Šï¼š{subset}ç›®å½•ä¸å­˜åœ¨ï¼Œå°†å°è¯•å…¶ä»–ç›®å½•ç»“æ„")
    
    elif structure_type == 2:
        # æ•°æ®é›†æŒ‰ç±»åˆ«åˆ†ç»„: data_dir/class/train, data_dir/class/val
        for class_dir in path.iterdir():
            if class_dir.is_dir():
                subset_dir = class_dir / subset
                if subset_dir.exists() and subset_dir.is_dir():
                    for img_path in subset_dir.rglob("*.*"):
                        if img_path.is_file() and img_path.suffix.lower() in ['.jpg', '.png', '.jpeg', '.bmp']:
                            rel_path = img_path.relative_to(path)
                            class_label = class_dir.name
                            records.append({
                                "filename": str(rel_path),
                                "label": class_label
                            })
    
    # å¦‚æœä¸Šé¢çš„æ–¹æ³•éƒ½æ²¡æœ‰æ‰¾åˆ°å›¾åƒï¼Œå°è¯•ç›´æ¥æŸ¥æ‰¾æ‰€æœ‰å›¾åƒ
    if not records:
        print("å°è¯•ç›´æ¥åœ¨æ•°æ®ç›®å½•ä¸­æŸ¥æ‰¾å›¾åƒ...")
        val_dir = path / subset
        if val_dir.exists() and val_dir.is_dir():
            # ä»…å¤„ç†valç›®å½•ä¸­çš„å›¾åƒ
            for img_path in val_dir.rglob("*.*"):
                if img_path.is_file() and img_path.suffix.lower() in ['.jpg', '.png', '.jpeg', '.bmp']:
                    rel_path = img_path.relative_to(path)
                    parts = rel_path.parts
                    
                    # ç¡®ä¿ä»valç›®å½•çš„ç›´æ¥å­ç›®å½•è·å–ç±»åˆ«åç§°
                    if len(parts) >= 2 and parts[0] == subset:
                        class_label = parts[1]  # val/<class_name>/...
                    else:
                        class_label = "unknown"
                        
                    records.append({
                        "filename": str(rel_path),
                        "label": class_label
                    })
        else:
            # åœ¨æ•´ä¸ªæ•°æ®ç›®å½•ä¸­æŸ¥æ‰¾
            for img_path in path.rglob("*.*"):
                if img_path.is_file() and img_path.suffix.lower() in ['.jpg', '.png', '.jpeg', '.bmp']:
                    rel_path = img_path.relative_to(path)
                    parts = rel_path.parts
                    
                    # å°è¯•ä»è·¯å¾„æ¨æ–­ç±»åˆ«
                    if subset in parts and len(parts) > parts.index(subset) + 1:
                        # å¦‚æœè·¯å¾„åŒ…å« 'val'ï¼Œåˆ™ä½¿ç”¨å…¶åçš„ç¬¬ä¸€ä¸ªç›®å½•ä½œä¸ºç±»åˆ«
                        class_label = parts[parts.index(subset) + 1]
                    elif len(parts) >= 2:
                        # å¦åˆ™ä½¿ç”¨å€’æ•°ç¬¬äºŒä¸ªéƒ¨åˆ†ä½œä¸ºç±»åˆ«
                        class_label = parts[-2]
                    else:
                        # æ— æ³•ç¡®å®šç±»åˆ«
                        class_label = "unknown"
                    
                    records.append({
                        "filename": str(rel_path),
                        "label": class_label
                    })
    
    print(f"æˆåŠŸåˆ›å»ºæ•°æ®é›†ï¼ŒåŒ…å« {len(records)} æ¡è®°å½•")
    # è¾“å‡ºæ ·æœ¬ç±»åˆ«ä¿¡æ¯
    if records:
        sample_labels = list(set([r['label'] for r in records[:min(100, len(records))]])) 
        print(f"æ•°æ®é›†åŒ…å«çš„ç±»åˆ«æ ·æœ¬ï¼š{sample_labels[:10]}...")
        
    df = pd.DataFrame(records)
    return df, path

def load_model(model_path, arch, device=None, data_path=None, img_size=320):
    """åŠ è½½æ¨¡å‹ï¼ˆæ”¯æŒåˆ†ç±»å’Œåˆ†å‰²ï¼‰
    
    Args:
        model_path: æ¨¡å‹è·¯å¾„
        arch: æ¨¡å‹æ¶æ„åç§°
        device: è®¾å¤‡ç±»å‹('cuda'æˆ–'cpu')
        data_path: æ•°æ®é›†è·¯å¾„ï¼Œç”¨äºä»æ•°æ®ç›®å½•è·å–ç±»åˆ«ä¿¡æ¯
        img_size: å›¾åƒå°ºå¯¸ï¼ˆåˆ†å‰²æ¨¡å‹éœ€è¦ï¼‰
    """
    print("å°è¯•åŠ è½½æ¨¡å‹...")
    
    # åˆ¤æ–­æ˜¯å¦ä¸ºåˆ†å‰²æ¨¡å‹
    is_segmentation = arch.lower().endswith('_seg')
    
    if is_segmentation:
        print(f"ğŸ¯ æ£€æµ‹åˆ°åˆ†å‰²æ¨¡å‹: {arch}")
        return load_segmentation_model(model_path, arch, device, img_size)
    else:
        print(f"ğŸ¯ æ£€æµ‹åˆ°åˆ†ç±»æ¨¡å‹: {arch}")
        return load_classification_model(model_path, arch, device, data_path)


def load_segmentation_model(model_path, arch, device=None, img_size=2048):
    """åŠ è½½åˆ†å‰²æ¨¡å‹
    
    Args:
        model_path: æ¨¡å‹è·¯å¾„
        arch: æ¨¡å‹æ¶æ„åç§°
        device: è®¾å¤‡ç±»å‹
        img_size: å›¾åƒå°ºå¯¸
    """
    from PIL import Image
    
    # åˆ›å»ºä¸´æ—¶æ•°æ®ç”¨äºåˆå§‹åŒ–
    print("åˆ›å»ºä¸´æ—¶åˆ†å‰²æ¨¡å‹...")
    temp_path = Path('.') / "temp_images"
    temp_path.mkdir(exist_ok=True)
    
    # åˆ›å»ºä¸´æ—¶å›¾åƒ
    if not list(temp_path.glob("*.jpg")):
        img = Image.new('RGB', (img_size, img_size), color='white')
        img.save(temp_path / "dummy.jpg")
        mask = Image.new('L', (img_size, img_size), color=0)
        mask.save(temp_path / "dummy_mask.png")
    
    # ä½¿ç”¨ get_model åˆ›å»ºåˆ†å‰²æ¨¡å‹
    if CUSTOM_MODELS_AVAILABLE:
        model = get_model(arch, n_classes=1, n_channels=3)
    else:
        raise ValueError(f"åˆ†å‰²æ¨¡å‹ '{arch}' éœ€è¦è‡ªå®šä¹‰æ¨¡å‹æ¨¡å—æ”¯æŒ")
    
    # åˆ›å»ºç®€å•çš„æ•°æ®åŠ è½½å™¨ç”¨äºåŒ…è£…
    from torch.utils.data import Dataset, DataLoader
    
    class DummySegDataset(Dataset):
        def __len__(self):
            return 1
        def __getitem__(self, idx):
            img = torch.rand(3, img_size, img_size)
            mask = torch.zeros(img_size, img_size)
            return TensorImage(img), TensorMask(mask)
    
    dummy_ds = DummySegDataset()
    dummy_dl = DataLoader(dummy_ds, batch_size=1)
    
    from fastai.vision.all import DataLoaders
    dls = DataLoaders(dummy_dl, dummy_dl)
    
    # åˆ›å»º Learnerï¼Œéœ€è¦æŒ‡å®šæŸå¤±å‡½æ•°
    from fastai.learner import Learner
    from torch.nn import BCEWithLogitsLoss
    
    loss_func = BCEWithLogitsLoss()
    learn = Learner(dls, model, loss_func=loss_func)
    
    # åŠ è½½æƒé‡
    print(f"ä» {model_path} åŠ è½½æƒé‡...")
    state_dict = torch.load(model_path, map_location='cpu' if device != 'cuda' else 'cuda')
    
    if isinstance(state_dict, dict) and 'model' in state_dict:
        state_dict = state_dict['model']
    
    learn.model.load_state_dict(state_dict)
    print("åˆ†å‰²æ¨¡å‹æƒé‡åŠ è½½æˆåŠŸ!")
    
    # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    learn.model.eval()
    
    return learn


def load_classification_model(model_path, arch, device=None, data_path=None):
    """åŠ è½½åˆ†ç±»æ¨¡å‹
    
    Args:
        model_path: æ¨¡å‹è·¯å¾„
        device: è®¾å¤‡ç±»å‹('cuda'æˆ–'cpu')
        data_path: æ•°æ®é›†è·¯å¾„ï¼Œç”¨äºä»æ•°æ®ç›®å½•è·å–ç±»åˆ«ä¿¡æ¯
    """
    print("å°è¯•åŠ è½½æ¨¡å‹...")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰é¢„å®šä¹‰ç±»åˆ«
    categories = None
    predefined_classes = os.environ.get('MODEL_CLASSES', None)
    if predefined_classes:
        categories = predefined_classes.split(',')
        print(f"ä½¿ç”¨é¢„å®šä¹‰ç±»åˆ«: {categories}")
    else:
        # å¦‚æœæä¾›äº†æ•°æ®è·¯å¾„ï¼Œä»æ•°æ®è·¯å¾„è·å–ç±»åˆ«
        if data_path:
            try:
                # ä»æŒ‡å®šçš„æ•°æ®è·¯å¾„è·å–ç±»åˆ«ä¿¡æ¯
                print(f"ä»æŒ‡å®šçš„æ•°æ®è·¯å¾„è·å–ç±»åˆ«: {data_path}")
                _, categories = detect_dataset_structure(data_path)
                if categories:
                    print(f"ä»æ•°æ®è·¯å¾„è·å–åˆ°ç±»åˆ«: {categories}")
                else:
                    print("ä»æ•°æ®è·¯å¾„æœªæ£€æµ‹åˆ°ç±»åˆ«ï¼Œå°†å°è¯•å…¶ä»–æ–¹æ³•...")
            except Exception as dpe:
                print(f"ä»æŒ‡å®šæ•°æ®è·¯å¾„è·å–ç±»åˆ«å¤±è´¥: {dpe}")
                categories = None
    
    if categories is None:
        print("é”™è¯¯ï¼šæœªæŒ‡å®šç±»åˆ«ã€‚è¯·ä½¿ç”¨ --classes æŒ‡å®šç±»åˆ«ï¼Œæˆ–ä½¿ç”¨ --data_path æŒ‡å®šæ•°æ®é›†è·¯å¾„ã€‚")
        exit(1)

    # åˆ›å»ºä¸€ä¸ªä¸´æ—¶æ•°æ®å—å¹¶æ„å»ºå­¦ä¹ å™¨
    print("åˆ›å»ºä¸´æ—¶æ¨¡å‹...")
    dblock = DataBlock(
        blocks=(ImageBlock, CategoryBlock(categories)),
        get_items=get_image_files,
        get_y=lambda x: categories[0]  # é»˜è®¤ç±»åˆ«ï¼Œç¨åä¼šè¢«é¢„æµ‹è¦†ç›–
    )
    
    # å°è¯•åˆ›å»ºä¸€ä¸ªä¸´æ—¶æ•°æ®åŠ è½½å™¨
    path = Path('.')
    temp_path = path / "temp_images"
    temp_path.mkdir(exist_ok=True)
    
    # ç¡®ä¿æœ‰è‡³å°‘ä¸€ä¸ªå›¾åƒè¿›è¡Œåˆå§‹åŒ–
    if not list(temp_path.glob("*.jpg")):
        # åˆ›å»ºä¸€ä¸ªç©ºç™½å›¾åƒ
        from PIL import Image
        img = Image.new('RGB', (320, 320), color='white')
        img.save(temp_path / "dummy.jpg")

    dls = dblock.dataloaders(temp_path, bs=1)

    print(dls.vocab)
    
    # ä½¿ç”¨ç±»åˆ«ä¿¡æ¯åˆ›å»ºæ–°çš„å­¦ä¹ å™¨
    # arch = os.environ.get('MODEL_ARCH', 'resnet18')  # ä»ç¯å¢ƒå˜é‡è·å–æˆ–ä½¿ç”¨é»˜è®¤å€¼
    print(f"ä½¿ç”¨æ¶æ„ {arch} åˆ›å»ºå­¦ä¹ å™¨")
    learn = vision_learner(dls, arch=arch, pretrained=False, n_out=len(dls.vocab))
    
    # åŠ è½½æƒé‡
    print(f"ä» {model_path} åŠ è½½æƒé‡...")
    state_dict = torch.load(model_path, map_location='cpu' if device != 'cuda' else 'cuda')
    
    print(f"æƒé‡é”®å: {state_dict.keys()}")

    # # å¤„ç†å¯èƒ½çš„DDPçŠ¶æ€
    if isinstance(state_dict, dict) and 'model' in state_dict:
        state_dict = state_dict['model']
    
    # # å¤„ç†å¯èƒ½çš„å¸¦'module.'å‰ç¼€çš„æƒé‡(DDP)
    # print(f"å¤„ç†å¯èƒ½çš„å¸¦'module.'å‰ç¼€çš„æƒé‡(DDP)")
    # if any(k.startswith('module.') for k in state_dict.keys()):
    #     print(k)
    #     from collections import OrderedDict
    #     new_state_dict = OrderedDict()
    #     for k, v in state_dict.items():
    #         name = k[7:] if k.startswith('module.') else k
    #         new_state_dict[name] = v
    #     state_dict = new_state_dict
    
    # åŠ è½½æ¨¡å‹æƒé‡
    learn.model.load_state_dict(state_dict)
    print("æ¨¡å‹æƒé‡åŠ è½½æˆåŠŸ!")
    
    return learn

def predict_segmentation(learn, img_path, img_size=2048):
    """é¢„æµ‹åˆ†å‰²æ©ç 
    
    Args:
        learn: FastAI Learner
        img_path: å›¾åƒè·¯å¾„
        img_size: å›¾åƒå°ºå¯¸
        
    Returns:
        pred_mask: é¢„æµ‹çš„æ©ç  (numpy array, åŸå§‹å›¾åƒå°ºå¯¸)
        original_size: åŸå§‹å›¾åƒå°ºå¯¸ (width, height)
    """
    from PIL import Image
    
    # åŠ è½½å¹¶é¢„å¤„ç†å›¾åƒ
    img = Image.open(img_path).convert('RGB')
    original_size = img.size  # (width, height)
    img_resized = img.resize((img_size, img_size), Image.BICUBIC)
    
    # è½¬æ¢ä¸ºtensor
    img_array = np.array(img_resized, dtype=np.float32) / 255.0
    img_tensor = torch.from_numpy(img_array).permute(2, 0, 1).unsqueeze(0)
    
    # ç§»åˆ°æ­£ç¡®çš„è®¾å¤‡
    device = next(learn.model.parameters()).device
    img_tensor = img_tensor.to(device)
    
    # é¢„æµ‹
    with torch.no_grad():
        pred = learn.model(img_tensor)
        pred_mask_resized = (pred.sigmoid() > 0.5).cpu().numpy()[0, 0]
    
    # å°†æ©ç æ¢å¤åˆ°åŸå§‹å›¾åƒå°ºå¯¸
    from PIL import Image
    mask_img = Image.fromarray((pred_mask_resized * 255).astype(np.uint8))
    mask_img_original = mask_img.resize(original_size, Image.NEAREST)
    pred_mask = (np.array(mask_img_original) > 127).astype(np.uint8)
    
    return pred_mask, original_size


def evaluate_segmentation_model(learn, data_path, img_size=2048, output_dir=None):
    """è¯„ä¼°åˆ†å‰²æ¨¡å‹
    
    Args:
        learn: FastAI Learner
        data_path: æ•°æ®è·¯å¾„
        img_size: å›¾åƒå°ºå¯¸
        output_dir: è¾“å‡ºç›®å½•ï¼ˆç”¨äºä¿å­˜å¯è§†åŒ–ç»“æœï¼‰
        
    Returns:
        results: è¯„ä¼°ç»“æœå­—å…¸
    """
    from PIL import Image
    
    print(f"å¼€å§‹è¯„ä¼°åˆ†å‰²æ¨¡å‹...")
    data_path = Path(data_path)
    
    # æŸ¥æ‰¾å›¾åƒå’Œæ©ç 
    img_dir = data_path / 'val' / 'images'
    mask_dir = data_path / 'val' / 'masks'
    
    if not img_dir.exists():
        # å°è¯•å…¶ä»–ç»“æ„
        img_dir = data_path / 'images' / 'val'
        mask_dir = data_path / 'masks' / 'val'
    
    if not img_dir.exists():
        raise ValueError(f"æ‰¾ä¸åˆ°å›¾åƒç›®å½•: {img_dir}")
    
    if not mask_dir.exists():
        print(f"âš ï¸  æ‰¾ä¸åˆ°æ©ç ç›®å½•: {mask_dir}ï¼Œå°†åªè¿›è¡Œé¢„æµ‹è€Œä¸è¯„ä¼°")
        has_masks = False
    else:
        has_masks = True
    
    # è·å–æ‰€æœ‰å›¾åƒ
    img_files = sorted(list(img_dir.glob('*.jpg')) + list(img_dir.glob('*.png')))
    
    if len(img_files) == 0:
        raise ValueError(f"åœ¨ {img_dir} ä¸­æœªæ‰¾åˆ°å›¾åƒ")
    
    print(f"æ‰¾åˆ° {len(img_files)} å¼ å›¾åƒ")
    
    # è¯„ä¼°
    dice_scores = []
    predictions = []
    
    device = next(learn.model.parameters()).device
    
    for img_path in tqdm(img_files, desc="è¯„ä¼°ä¸­"):
        try:
            # åŠ è½½å›¾åƒ
            img = Image.open(img_path).convert('RGB')
            img_resized = img.resize((img_size, img_size), Image.BICUBIC)
            
            # è½¬æ¢ä¸ºtensor
            img_array = np.array(img_resized, dtype=np.float32) / 255.0
            img_tensor = torch.from_numpy(img_array).permute(2, 0, 1).unsqueeze(0).to(device)
            
            # é¢„æµ‹
            with torch.no_grad():
                pred = learn.model(img_tensor)
                pred_prob = pred.sigmoid()
                pred_mask = (pred_prob > 0.5).cpu().numpy()[0, 0]
            
            # å¦‚æœæœ‰çœŸå®æ©ç ï¼Œè®¡ç®—Dice score
            dice = None
            if has_masks:
                base_name = img_path.stem
                mask_name = f"{base_name}_mask.png"
                mask_path = mask_dir / mask_name
                
                if not mask_path.exists():
                    mask_name = f"{base_name}.png"
                    mask_path = mask_dir / mask_name
                
                if mask_path.exists():
                    mask = Image.open(mask_path).convert('L')
                    mask_resized = mask.resize((img_size, img_size), Image.NEAREST)
                    mask_array = (np.array(mask_resized) > 127).astype(np.uint8)
                    
                    # è®¡ç®—Dice score
                    mask_tensor = torch.from_numpy(mask_array).unsqueeze(0).unsqueeze(0).float().to(device)
                    dice = dice_score(pred, mask_tensor).item()
                    dice_scores.append(dice)
            
            predictions.append({
                'image_path': str(img_path),
                'dice_score': dice,
                'has_mask': dice is not None
            })
            
        except Exception as e:
            print(f"å¤„ç† {img_path} æ—¶å‡ºé”™: {e}")
    
    # è®¡ç®—ç»Ÿè®¡
    results = {
        'predictions': predictions,
        'num_images': len(img_files),
    }
    
    if dice_scores:
        results['mean_dice'] = float(np.mean(dice_scores))
        results['std_dice'] = float(np.std(dice_scores))
        results['min_dice'] = float(np.min(dice_scores))
        results['max_dice'] = float(np.max(dice_scores))
        
        print(f"\nğŸ“Š åˆ†å‰²è¯„ä¼°ç»“æœ:")
        print(f"  å¹³å‡ Dice Score: {results['mean_dice']:.4f} Â± {results['std_dice']:.4f}")
        print(f"  æœ€å° Dice Score: {results['min_dice']:.4f}")
        print(f"  æœ€å¤§ Dice Score: {results['max_dice']:.4f}")
    
    return results


def evaluate_model(learn, test_df, data_path):
    """è¯„ä¼°åˆ†ç±»æ¨¡å‹æ€§èƒ½"""
    # æ”¶é›†çœŸå®æ ‡ç­¾å’Œé¢„æµ‹ç»“æœ
    true_labels = []
    pred_labels = []
    image_paths = []
    probabilities = []
    
    # ç›´æ¥é€ä¸ªå›¾åƒé¢„æµ‹
    print("é€å›¾åƒé¢„æµ‹ä¸­...")
    for i, row in tqdm(test_df.iterrows(), total=len(test_df), desc="è¯„ä¼°ä¸­"):
        try:
            # æ„å»ºå›¾åƒè·¯å¾„
            img_path = data_path / row['filename']
            if not img_path.exists():
                print(f"è­¦å‘Šï¼šå›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {img_path}")
                continue
                
            image_paths.append(str(img_path))
            
            # è·å–çœŸå®æ ‡ç­¾
            true_label = row["label"]
            true_labels.append(true_label)
            
            # é¢„æµ‹
            img = PILImage.create(img_path)
            pred_class, pred_idx, probs = learn.predict(img)
#            print(pred_class, pred_idx, probs )
            pred_labels.append(str(pred_class))
            probabilities.append({str(c): float(p) for c, p in zip(learn.dls.vocab, map(float, probs))})
        except Exception as e:
            print(f"é¢„æµ‹å›¾åƒ {row['filename']} æ—¶å‡ºé”™: {e}")
    
    # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
    if not true_labels or not pred_labels:
        raise ValueError("æ²¡æœ‰æœ‰æ•ˆçš„é¢„æµ‹ç»“æœ")
        
    # å¯¹é½æ ‡ç­¾
    unique_labels = sorted(list(set(true_labels + pred_labels)))
    
    # ä½¿ç”¨å…±åŒæ ‡ç­¾è®¡ç®—æ€§èƒ½æŒ‡æ ‡
    report = classification_report(true_labels, pred_labels, labels=unique_labels, output_dict=True)
    cm = confusion_matrix(true_labels, pred_labels, labels=unique_labels)
    
    # ç»„ç»‡ç»“æœ
    results = {
        "individual_predictions": [
            {
                "image_path": path,
                "true_label": true,
                "predicted_label": pred,
                "probabilities": prob
            }
            for path, true, pred, prob in zip(image_paths, true_labels, pred_labels, probabilities)
        ],
        "classification_report": report,
        "confusion_matrix": cm.tolist(),
        "confusion_matrix_labels": unique_labels
    }
    
    return results

def save_results(results, output_path, is_segmentation=False):
    """ä¿å­˜é¢„æµ‹ç»“æœå’Œè¯„ä¼°æŒ‡æ ‡
    
    Args:
        results: è¯„ä¼°ç»“æœå­—å…¸
        output_path: è¾“å‡ºè·¯å¾„
        is_segmentation: æ˜¯å¦ä¸ºåˆ†å‰²ä»»åŠ¡
    """
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(output_path).parent
    output_dir.mkdir(exist_ok=True, parents=True)
    
    # ä¿å­˜JSONç»“æœ
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print(f"ç»“æœå·²ä¿å­˜åˆ° {output_path}")
    
    # å¦‚æœæ˜¯åˆ†å‰²ä»»åŠ¡ï¼Œä¸éœ€è¦ç”Ÿæˆåˆ†ç±»æŠ¥å‘Šå›¾è¡¨
    if is_segmentation:
        print("åˆ†å‰²ä»»åŠ¡è¯„ä¼°å®Œæˆ")
        return
    
    # åˆ›å»ºæŠ¥å‘Šç›®å½•
    report_dir = output_dir / "reports"
    report_dir.mkdir(exist_ok=True)
    
    # æå–åˆ†ç±»æŠ¥å‘Š
    report = results["classification_report"]
    
    # ç”Ÿæˆæ€§èƒ½æŒ‡æ ‡å›¾è¡¨
    metrics = ['precision', 'recall', 'f1-score']
    plt.figure(figsize=(12, 8))
    
    for i, metric in enumerate(metrics):
        plt.subplot(1, 3, i+1)
        
        # æ’é™¤'accuracy', 'macro avg', 'weighted avg'
        metric_data = {k: report[k][metric] for k in report if k not in ['accuracy', 'macro avg', 'weighted avg']}
        
        # æŒ‰å€¼æ’åºæ˜¾ç¤º
        sorted_data = {k: v for k, v in sorted(metric_data.items(), key=lambda item: item[1], reverse=True)}
        
        # åˆ›å»ºæ¡å½¢å›¾
        plt.bar(sorted_data.keys(), sorted_data.values())
        plt.title(f"{metric.capitalize()} by Class")
        plt.xticks(rotation=45, ha='right')
        plt.ylim(0, 1.0)
        plt.tight_layout()
    
    plt.savefig(report_dir / "metrics_by_class.png")
    
    # ç»˜åˆ¶æ··æ·†çŸ©é˜µ
    plt.figure(figsize=(16, 14))
    labels = results["confusion_matrix_labels"]
    cm = np.array(results["confusion_matrix"])
    
    # è®¡ç®—å½’ä¸€åŒ–æ··æ·†çŸ©é˜µ
    cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
    cm_norm = np.nan_to_num(cm_norm)  # å¤„ç†é™¤ä»¥0çš„æƒ…å†µ
    
    ax = sns.heatmap(cm_norm, annot=True, fmt='.2f', cmap='Blues',
                    xticklabels=labels, yticklabels=labels)
    ax.set_xlabel('Predicted Labels')
    ax.set_ylabel('True Labels')
    plt.title('Normalized Confusion Matrix')
    plt.tight_layout()
    plt.savefig(report_dir / "confusion_matrix.png")
    
    print(f"æŠ¥å‘Šå›¾è¡¨å·²ä¿å­˜åˆ° {report_dir}")
    
    # æ‰“å°æ€»ä½“æ€§èƒ½
    print("\næ¨¡å‹æ€»ä½“æ€§èƒ½:")
    print(f"å‡†ç¡®ç‡(Accuracy): {report['accuracy']:.4f}")
    print(f"å®å¹³å‡(Macro Avg) - ç²¾ç¡®ç‡: {report['macro avg']['precision']:.4f}, å¬å›ç‡: {report['macro avg']['recall']:.4f}, F1-Score: {report['macro avg']['f1-score']:.4f}")
    print(f"åŠ æƒå¹³å‡(Weighted Avg) - ç²¾ç¡®ç‡: {report['weighted avg']['precision']:.4f}, å¬å›ç‡: {report['weighted avg']['recall']:.4f}, F1-Score: {report['weighted avg']['f1-score']:.4f}")

def predict_single_image(model_path, image_path, arch='resnet18', device=None, classes=None, data_path=None, img_size=320, save_mask=False):
    """é¢„æµ‹å•å¼ å›¾ç‰‡çš„ç±»åˆ«æˆ–åˆ†å‰²æ©ç 
    
    Args:
        model_path: æ¨¡å‹è·¯å¾„(.pth æˆ– .pkl)
        image_path: å›¾ç‰‡è·¯å¾„
        arch: æ¨¡å‹æ¶æ„
        device: è¿è¡Œè®¾å¤‡ ('cuda' æˆ– 'cpu')
        classes: ç±»åˆ«åˆ—è¡¨ï¼Œå¦‚æœä¸ºNoneåˆ™å°è¯•ä»æ¨¡å‹ä¸­è·å–
        data_path: æ•°æ®é›†è·¯å¾„ï¼Œç”¨äºä»æ•°æ®ç›®å½•è·å–ç±»åˆ«ä¿¡æ¯
        img_size: å›¾åƒå°ºå¯¸
        save_mask: æ˜¯å¦ä¿å­˜é¢„æµ‹æ©ç ï¼ˆåˆ†å‰²ä»»åŠ¡ï¼‰
    """
    print(f"\n===== é¢„æµ‹å•å¼ å›¾ç‰‡ =====")
    print(f"å›¾ç‰‡: {image_path}")
    print(f"æ¨¡å‹: {model_path}")
    print(f"æ¶æ„: {arch}")
    if data_path:
        print(f"æ•°æ®è·¯å¾„: {data_path}")
    
    # ç¡®ä¿å›¾ç‰‡å­˜åœ¨
    img_path = Path(image_path)
    if not img_path.exists():
        print(f"é”™è¯¯: æ‰¾ä¸åˆ°å›¾ç‰‡: {image_path}")
        return
    
    # åˆ¤æ–­æ˜¯å¦ä¸ºåˆ†å‰²æ¨¡å‹
    is_segmentation = arch.lower().endswith('_seg')
    
    # åŠ è½½æ¨¡å‹
    start_time = time.time()
    
    try:
        # åŠ è½½æ¨¡å‹
        learn = load_model(model_path, arch, device, data_path, img_size)
        load_time = time.time() - start_time
        
        if is_segmentation:
            # åˆ†å‰²ä»»åŠ¡é¢„æµ‹
            inference_start = time.time()
            pred_mask, original_size = predict_segmentation(learn, img_path, img_size)
            inference_time = time.time() - inference_start
            
            print(f"\né¢„æµ‹ç»“æœ:")
            print(f"åŸå§‹å›¾åƒå°ºå¯¸: {original_size}")
            print(f"æ©ç å½¢çŠ¶: {pred_mask.shape}")
            print(f"å‰æ™¯åƒç´ å æ¯”: {pred_mask.sum() / pred_mask.size * 100:.2f}%")
            
            # ä¿å­˜é¢„æµ‹æ©ç 
            if save_mask:
                from PIL import Image
                output_path = Path.cwd() / f"{img_path.stem}_pred_mask.png"
                mask_img = Image.fromarray((pred_mask * 255).astype(np.uint8))
                mask_img.save(output_path)
                print(f"é¢„æµ‹æ©ç å·²ä¿å­˜åˆ°: {output_path}")
            
        else:
            # åˆ†ç±»ä»»åŠ¡é¢„æµ‹
            img = PILImage.create(img_path)
            
            inference_start = time.time()
            pred_class, pred_idx, probs = learn.predict(img)
            inference_time = time.time() - inference_start
            
            print(f"è¾“å‡º: {pred_class} {pred_idx} {probs}")
            print(f"\né¢„æµ‹ç»“æœ:")
            print(f"ç±»åˆ«: {pred_class}")
            print(f"ç½®ä¿¡åº¦: {float(probs[pred_idx]):.4f}")
            
            # æ˜¾ç¤ºå‰5ä¸ªæœ€é«˜æ¦‚ç‡çš„ç±»åˆ«
            top_k_values, top_k_indices = torch.topk(probs, min(5, len(probs)))
            
            print("\nå‰5ä¸ªé¢„æµ‹:")
            for i, (idx, prob) in enumerate(zip(top_k_indices, top_k_values), 1):
                print(f"{i}. {learn.dls.vocab[idx]}: {float(prob):.4f}")
        
        print(f"\næ¨¡å‹åŠ è½½æ—¶é—´: {load_time*1000:.2f}ms")
        print(f"æ¨ç†æ—¶é—´: {inference_time*1000:.2f}ms")
        print(f"æ€»æ—¶é—´: {(time.time() - start_time)*1000:.2f}ms")
        
    except Exception as e:
        print(f"é¢„æµ‹æ—¶å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()


def load_onnx_model(model_path, device=None, data_path=None):
    """åŠ è½½ONNXæ¨¡å‹å¹¶ç¡®ä¿ç±»åˆ«é¡ºåºä¸€è‡´"""
    print(f"å°è¯•åŠ è½½ONNXæ¨¡å‹: {model_path}")
    
    try:
        import onnx
        
        # è®¾ç½®æ‰§è¡Œæä¾›ç¨‹åº
        if device == 'cuda' and 'CUDAExecutionProvider' in onnx.get_available_providers():
            providers = ['CUDAExecutionProvider', 'CPUExecutionProvider']
            print("ä½¿ç”¨CUDAæ‰§è¡ŒONNXæ¨¡å‹")
        else:
            providers = ['CPUExecutionProvider']
            print("ä½¿ç”¨CPUæ‰§è¡ŒONNXæ¨¡å‹")
        
        # åŠ è½½ONNXæ¨¡å‹
        model = onnx.load(model_path)

        # è·å–ç±»åˆ«ä¿¡æ¯çš„ä¼˜å…ˆçº§ï¼š
        # 1. ä»æ¨¡å‹å…ƒæ•°æ®ä¸­è·å–
        # 2. ä»ç¯å¢ƒå˜é‡è·å–
        # 3. ä»æ•°æ®è·¯å¾„è·å–
        
        categories = None
        class_indices_map = None
        
        # 1. é¦–å…ˆå°è¯•ä»æ¨¡å‹å…ƒæ•°æ®è·å–
        for meta in model.metadata_props:
            if meta.key == "classes":
                categories = meta.value.split(",")
                print(f"ä»ONNXæ¨¡å‹å…ƒæ•°æ®è·å–ç±»åˆ«: {categories}")
                break
                
            # æ£€æŸ¥æ˜¯å¦æœ‰å¸¦ç´¢å¼•çš„ç±»åˆ«ä¿¡æ¯
            if meta.key == "class_indices" and not categories:
                index_class_pairs = meta.value.split(",")
                class_indices_map = {}
                for pair in index_class_pairs:
                    idx, class_name = pair.split(":")
                    class_indices_map[int(idx)] = class_name
                
                # æŒ‰ç´¢å¼•æ’åºç±»åˆ«
                if class_indices_map:
                    categories = [class_indices_map[i] for i in range(len(class_indices_map))]
                    print(f"ä»ONNXæ¨¡å‹å…ƒæ•°æ®è·å–æœ‰åºç±»åˆ«: {categories}")
        
        # 2. å°è¯•ä»ç¯å¢ƒå˜é‡è·å–
        if not categories:
            predefined_classes = os.environ.get('MODEL_CLASSES', None)
            if predefined_classes:
                categories = predefined_classes.split(',')
                print(f"ä½¿ç”¨é¢„å®šä¹‰ç±»åˆ«: {categories}")
        
        # 3. ä»æ•°æ®è·¯å¾„è·å–
        if not categories and data_path:
            try:
                print(f"ä»æ•°æ®è·¯å¾„è·å–ç±»åˆ«: {data_path}")
                # ä½¿ç”¨ä¸è®­ç»ƒæ—¶ç›¸åŒçš„æ–¹æ³•æ„å»ºç±»åˆ«åˆ—è¡¨
                test_df, _ = build_test_df(data_path)
                if len(test_df) > 0:
                    # ç¡®ä¿æŒ‰å­—æ¯æ’åºï¼Œä¸å¤§å¤šæ•°æ•°æ®é›†åŠ è½½å™¨ä¸€è‡´
                    categories = sorted(test_df['label'].unique().tolist())
                    print(f"ä»æ•°æ®è·¯å¾„è·å–å¹¶æ’åºç±»åˆ«: {categories}")
            except Exception as dpe:
                print(f"ä»æ•°æ®è·¯å¾„è·å–ç±»åˆ«å¤±è´¥: {dpe}")
        
        # å¦‚æœä»ç„¶æ²¡æœ‰ç±»åˆ«ï¼Œç»™å‡ºé”™è¯¯
        if not categories:
            print("é”™è¯¯: æœªæ‰¾åˆ°ç±»åˆ«ä¿¡æ¯ã€‚è¯·ä½¿ç”¨--classeså‚æ•°æŒ‡å®šç±»åˆ«ï¼Œæˆ–ä½¿ç”¨--data_pathæŒ‡å®šæ•°æ®é›†è·¯å¾„ã€‚")
            exit(1)

        # ä½¿ç”¨onnxruntimeè¿è¡Œæ¨¡å‹
        import onnxruntime as ort
        session = ort.InferenceSession(model_path, providers=providers)

        input_name = session.get_inputs()[0].name

        return session, input_name, categories
        
    except ImportError:
        print("é”™è¯¯: æœªå®‰è£…onnxã€‚è¯·ä½¿ç”¨pip install onnxå®‰è£…ã€‚")
        exit(1)
    except Exception as e:
        print(f"åŠ è½½ONNXæ¨¡å‹å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        exit(1)

def preprocess_image_for_onnx(img_path, img_size=320):
    """é¢„å¤„ç†å›¾åƒç”¨äºONNXæ¨¡å‹æ¨ç†
    
    Args:
        img_path: å›¾åƒè·¯å¾„
        img_size: è¾“å…¥å›¾åƒå¤§å°
    
    Returns:
        preprocessed_img: é¢„å¤„ç†åçš„å›¾åƒï¼ˆnumpyæ•°ç»„ï¼‰
    """
    from PIL import Image
    import numpy as np
    
    # æ‰“å¼€å›¾åƒ
    img = Image.open(img_path).convert('RGB')
    
    # è°ƒæ•´å¤§å°
    img = img.resize((img_size, img_size), Image.LANCZOS)
    
    # è½¬æ¢ä¸ºnumpyæ•°ç»„ï¼Œå¹¶è¿›è¡Œæ ‡å‡†åŒ– [0,1]
    img_array = np.array(img, dtype=np.float32) / 255.0  # æ˜¾å¼æŒ‡å®šä¸ºfloat32
    
    # è½¬æ¢ä¸ºNCHWæ ¼å¼ (æ‰¹æ¬¡, é€šé“, é«˜åº¦, å®½åº¦)
    img_array = img_array.transpose(2, 0, 1)
    img_array = np.expand_dims(img_array, axis=0)
    
    # æœ€åç¡®è®¤ä¸€æ¬¡æ•°æ®ç±»å‹
    img_array = img_array.astype(np.float32)
    
    # æ‰“å°æ•°ç»„ä¿¡æ¯ä»¥ä¾¿è°ƒè¯•
    print(f"é¢„å¤„ç†åå›¾åƒå½¢çŠ¶: {img_array.shape}, æ•°æ®ç±»å‹: {img_array.dtype}")
    
    return img_array

def predict_with_onnx(session, input_name, img_array, categories):
    """ä½¿ç”¨ONNXæ¨¡å‹è¿›è¡Œé¢„æµ‹
    
    Args:
        session: ONNXè¿è¡Œæ—¶ä¼šè¯
        input_name: æ¨¡å‹è¾“å…¥åç§°
        img_array: é¢„å¤„ç†åçš„å›¾åƒæ•°ç»„
        categories: ç±»åˆ«åˆ—è¡¨
    
    Returns:
        pred_class: é¢„æµ‹çš„ç±»åˆ«
        pred_idx: é¢„æµ‹çš„ç±»åˆ«ç´¢å¼•
        probs: æ‰€æœ‰ç±»åˆ«çš„æ¦‚ç‡
    """
    import numpy as np
    
    # ç¡®ä¿è¾“å…¥æ˜¯float32ç±»å‹
    if img_array.dtype != np.float32:
        print(f"è­¦å‘Š: è¾“å…¥æ•°ç»„ç±»å‹ä¸º {img_array.dtype}ï¼Œè½¬æ¢ä¸º float32")
        img_array = img_array.astype(np.float32)
    
    # å‡†å¤‡è¾“å…¥
    input_dict = {input_name: img_array}
    
    # # è·å–æ¨¡å‹é¢„æœŸçš„è¾“å…¥ç±»å‹
    # input_details = session.get_inputs()
    # print(f"æ¨¡å‹è¾“å…¥è¯¦æƒ…: åç§°={input_details[0].name}, ç±»å‹={input_details[0].type}, å½¢çŠ¶={input_details[0].shape}")
    
    # æ‰§è¡Œæ¨ç†
    try:
        outputs = session.run(None, input_dict)
    except Exception as e:
        print(f"ONNXæ¨ç†å‡ºé”™: {e}")
        print(f"è¾“å…¥æ•°ç»„ä¿¡æ¯: å½¢çŠ¶={img_array.shape}, ç±»å‹={img_array.dtype}, æ•°å€¼èŒƒå›´=[{np.min(img_array)}, {np.max(img_array)}]")
        raise
    
    # è·å–è¾“å‡ºï¼ˆé€šå¸¸æ˜¯logitsï¼‰
    logits = outputs[0]
    # print(f"è¾“å‡ºlogitså½¢çŠ¶: {logits.shape}, ç±»å‹: {logits.dtype}, {outputs}")
    
    # åº”ç”¨softmaxè·å–æ¦‚ç‡
    # ä½¿ç”¨æ›´ç¨³å®šçš„softmaxå®ç°
    logits = logits - np.max(logits, axis=1, keepdims=True)  # ä¸ºäº†æ•°å€¼ç¨³å®šæ€§
    exp_logits = np.exp(logits)
    probs = exp_logits / np.sum(exp_logits, axis=1, keepdims=True)
    probs = probs[0]  # è·å–ç¬¬ä¸€ä¸ªæ‰¹æ¬¡çš„ç»“æœ
    
    # è·å–é¢„æµ‹ç±»åˆ«
    pred_idx = np.argmax(probs)
    pred_class = categories[pred_idx]
    
    return pred_class, pred_idx, probs

def predict_single_image_onnx(model_path, image_path, device=None, img_size=320, classes=None, data_path=None):
    """ä½¿ç”¨ONNXæ¨¡å‹é¢„æµ‹å•å¼ å›¾ç‰‡
    
    Args:
        model_path: ONNXæ¨¡å‹è·¯å¾„
        image_path: å›¾ç‰‡è·¯å¾„
        device: è¿è¡Œè®¾å¤‡ ('cuda' æˆ– 'cpu')
        img_size: å›¾åƒå¤§å°
        classes: ç±»åˆ«åˆ—è¡¨ï¼Œå¦‚æœä¸ºNoneåˆ™å°è¯•ä»æ¨¡å‹ä¸­è·å–
        data_path: æ•°æ®é›†è·¯å¾„ï¼Œç”¨äºä»æ•°æ®ç›®å½•è·å–ç±»åˆ«ä¿¡æ¯
    """
    print(f"\n===== ä½¿ç”¨ONNXæ¨¡å‹é¢„æµ‹å•å¼ å›¾ç‰‡ =====")
    print(f"å›¾ç‰‡: {image_path}")
    print(f"æ¨¡å‹: {model_path}")
    if data_path:
        print(f"æ•°æ®è·¯å¾„: {data_path}")
    
    # ç¡®ä¿å›¾ç‰‡å­˜åœ¨
    img_path = Path(image_path)
    if not img_path.exists():
        print(f"é”™è¯¯: æ‰¾ä¸åˆ°å›¾ç‰‡: {image_path}")
        return
    
    # å¦‚æœæä¾›äº†ç±»åˆ«åˆ—è¡¨ï¼Œä½¿ç”¨å®ƒ
    if classes:
        categories = [c.strip() for c in classes.split(',')]
        os.environ['MODEL_CLASSES'] = ','.join(categories)
        print(f"ä½¿ç”¨æŒ‡å®šçš„ç±»åˆ«åˆ—è¡¨: {categories}")
    
    # åŠ è½½æ¨¡å‹
    start_time = time.time()
    
    try:
        # åŠ è½½ONNXæ¨¡å‹
        session, input_name, categories = load_onnx_model(model_path, device, data_path)
        load_time = time.time() - start_time
        
        # é¢„å¤„ç†å›¾åƒ
        preprocess_start = time.time()
        img_array = preprocess_image_for_onnx(img_path, img_size)
        preprocess_time = time.time() - preprocess_start
        
        # æ‰§è¡Œæ¨ç†
        inference_start = time.time()
        pred_class, pred_idx, probs = predict_with_onnx(session, input_name, img_array, categories)
        inference_time = time.time() - inference_start
        
        # è¾“å‡ºç»“æœ
        print(f"\né¢„æµ‹ç»“æœ:")
        print(f"ç±»åˆ«: {pred_class}")
        print(f"ç½®ä¿¡åº¦: {float(probs[pred_idx]):.4f}")
        
        # æ˜¾ç¤ºå‰5ä¸ªæœ€é«˜æ¦‚ç‡çš„ç±»åˆ«
        top_k_indices = np.argsort(probs)[::-1]
        
        print("\né¢„æµ‹:")
        for i, idx in enumerate(top_k_indices, 1):
            print(f"{i}. {categories[idx]}: {float(probs[idx]):.4f}")
        
        print(f"\næ¨¡å‹åŠ è½½æ—¶é—´: {load_time*1000:.2f}ms")
        print(f"å›¾åƒé¢„å¤„ç†æ—¶é—´: {preprocess_time*1000:.2f}ms")
        print(f"æ¨ç†æ—¶é—´: {inference_time*1000:.2f}ms")
        print(f"æ€»æ—¶é—´: {(time.time() - start_time)*1000:.2f}ms")
        
    except Exception as e:
        print(f"é¢„æµ‹æ—¶å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

def predict_single_image_onnx_seg(model_path, image_path, device=None, img_size=2048, save_mask=True):
    """ä½¿ç”¨ONNXæ¨¡å‹é¢„æµ‹å•å¼ å›¾ç‰‡ï¼ˆåˆ†å‰²ä»»åŠ¡ï¼‰
    
    Args:
        model_path: ONNXæ¨¡å‹è·¯å¾„
        image_path: å›¾ç‰‡è·¯å¾„
        device: è¿è¡Œè®¾å¤‡ ('cuda' æˆ– 'cpu')
        img_size: å›¾åƒå¤§å°
        save_mask: æ˜¯å¦ä¿å­˜é¢„æµ‹æ©ç 
    """
    print(f"\n===== ä½¿ç”¨ONNXæ¨¡å‹é¢„æµ‹å•å¼ å›¾ç‰‡ï¼ˆåˆ†å‰²ï¼‰=====")
    print(f"å›¾ç‰‡: {image_path}")
    print(f"æ¨¡å‹: {model_path}")
    
    # ç¡®ä¿å›¾ç‰‡å­˜åœ¨
    img_path = Path(image_path)
    if not img_path.exists():
        print(f"é”™è¯¯: æ‰¾ä¸åˆ°å›¾ç‰‡: {image_path}")
        return
    
    # åŠ è½½æ¨¡å‹
    start_time = time.time()
    
    try:
        import onnxruntime as ort
        from PIL import Image
        
        # è®¾ç½®æ‰§è¡Œæä¾›ç¨‹åº
        if device == 'cuda' and 'CUDAExecutionProvider' in ort.get_available_providers():
            providers = ['CUDAExecutionProvider', 'CPUExecutionProvider']
            print("ä½¿ç”¨CUDAæ‰§è¡ŒONNXæ¨¡å‹")
        else:
            providers = ['CPUExecutionProvider']
            print("ä½¿ç”¨CPUæ‰§è¡ŒONNXæ¨¡å‹")
        
        # åŠ è½½ONNXæ¨¡å‹
        session = ort.InferenceSession(model_path, providers=providers)
        input_name = session.get_inputs()[0].name
        load_time = time.time() - start_time
        
        # åŠ è½½å›¾åƒ
        img = Image.open(img_path).convert('RGB')
        original_size = img.size  # (width, height)
        
        # é¢„å¤„ç†å›¾åƒ
        preprocess_start = time.time()
        img_resized = img.resize((img_size, img_size), Image.BICUBIC)
        img_array = np.array(img_resized, dtype=np.float32) / 255.0
        img_array = img_array.transpose(2, 0, 1)
        img_array = np.expand_dims(img_array, axis=0)
        preprocess_time = time.time() - preprocess_start
        
        # æ‰§è¡Œæ¨ç†
        inference_start = time.time()
        input_dict = {input_name: img_array}
        outputs = session.run(None, input_dict)
        inference_time = time.time() - inference_start
        
        # è·å–è¾“å‡º
        logits = outputs[0][0, 0]  # [H, W]
        
        # åº”ç”¨sigmoidå¹¶äºŒå€¼åŒ–
        pred_mask_resized = (1 / (1 + np.exp(-logits)) > 0.5).astype(np.uint8)
        
        # æ¢å¤åˆ°åŸå§‹å°ºå¯¸
        mask_img = Image.fromarray((pred_mask_resized * 255).astype(np.uint8))
        mask_img_original = mask_img.resize(original_size, Image.NEAREST)
        pred_mask = (np.array(mask_img_original) > 127).astype(np.uint8)
        
        # è¾“å‡ºç»“æœ
        print(f"\né¢„æµ‹ç»“æœ:")
        print(f"åŸå§‹å›¾åƒå°ºå¯¸: {original_size}")
        print(f"æ©ç å½¢çŠ¶: {pred_mask.shape}")
        print(f"å‰æ™¯åƒç´ å æ¯”: {pred_mask.sum() / pred_mask.size * 100:.2f}%")
        
        # ä¿å­˜é¢„æµ‹æ©ç 
        if save_mask:
            output_path = Path.cwd() / f"{img_path.stem}_pred_mask.png"
            mask_img_save = Image.fromarray((pred_mask * 255).astype(np.uint8))
            mask_img_save.save(output_path)
            print(f"é¢„æµ‹æ©ç å·²ä¿å­˜åˆ°: {output_path}")
        
        print(f"\næ¨¡å‹åŠ è½½æ—¶é—´: {load_time*1000:.2f}ms")
        print(f"å›¾åƒé¢„å¤„ç†æ—¶é—´: {preprocess_time*1000:.2f}ms")
        print(f"æ¨ç†æ—¶é—´: {inference_time*1000:.2f}ms")
        print(f"æ€»æ—¶é—´: {(time.time() - start_time)*1000:.2f}ms")
        
    except ImportError:
        print("é”™è¯¯: æœªå®‰è£…onnxruntimeã€‚è¯·ä½¿ç”¨pip install onnxruntimeå®‰è£…ã€‚")
    except Exception as e:
        print(f"é¢„æµ‹æ—¶å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()


def evaluate_model_onnx(model_path, test_df, data_path, device=None, img_size=320, classes=None):
    """ä½¿ç”¨ONNXæ¨¡å‹è¯„ä¼°æ•°æ®é›†
    
    Args:
        model_path: ONNXæ¨¡å‹è·¯å¾„
        test_df: æµ‹è¯•æ•°æ®é›†çš„DataFrame
        data_path: æ•°æ®é›†è·¯å¾„
        device: è¿è¡Œè®¾å¤‡ ('cuda' æˆ– 'cpu')
        img_size: å›¾åƒå¤§å°
        classes: ç±»åˆ«åˆ—è¡¨ï¼Œå¦‚æœä¸ºNoneåˆ™å°è¯•ä»æ¨¡å‹ä¸­è·å–
    
    Returns:
        results: è¯„ä¼°ç»“æœå­—å…¸
    """
    
    # å¦‚æœæä¾›äº†ç±»åˆ«åˆ—è¡¨ï¼Œä½¿ç”¨å®ƒ
    if classes:
        categories = [c.strip() for c in classes.split(',')]
        os.environ['MODEL_CLASSES'] = ','.join(categories)
    
    # åŠ è½½ONNXæ¨¡å‹
    session, input_name, categories = load_onnx_model(model_path, device, data_path)
    
    # æ”¶é›†çœŸå®æ ‡ç­¾å’Œé¢„æµ‹ç»“æœ
    true_labels = []
    pred_labels = []
    image_paths = []
    probabilities = []
    
    # ç›´æ¥é€ä¸ªå›¾åƒé¢„æµ‹
    print("é€å›¾åƒé¢„æµ‹ä¸­...")
    for i, row in tqdm(test_df.iterrows(), total=len(test_df), desc="è¯„ä¼°ä¸­"):
        try:
            # æ„å»ºå›¾åƒè·¯å¾„
            img_path = data_path / row['filename']
            if not img_path.exists():
                print(f"è­¦å‘Šï¼šå›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {img_path}")
                continue
                
            image_paths.append(str(img_path))
            
            # è·å–çœŸå®æ ‡ç­¾
            true_label = row["label"]
            true_labels.append(true_label)
            
            # é¢„å¤„ç†å›¾åƒ
            img_array = preprocess_image_for_onnx(img_path, img_size)
            
            # æ‰§è¡Œæ¨ç†
            pred_class, pred_idx, probs = predict_with_onnx(session, input_name, img_array, categories)
            
            pred_labels.append(str(pred_class))
            probabilities.append({str(c): float(p) for c, p in zip(categories, map(float, probs))})
        except Exception as e:
            print(f"é¢„æµ‹å›¾åƒ {row['filename']} æ—¶å‡ºé”™: {e}")
    
    # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
    if not true_labels or not pred_labels:
        raise ValueError("æ²¡æœ‰æœ‰æ•ˆçš„é¢„æµ‹ç»“æœ")
        
    # å¯¹é½æ ‡ç­¾
    unique_labels = sorted(list(set(true_labels + pred_labels)))
    
    # ä½¿ç”¨å…±åŒæ ‡ç­¾è®¡ç®—æ€§èƒ½æŒ‡æ ‡
    report = classification_report(true_labels, pred_labels, labels=unique_labels, output_dict=True)
    cm = confusion_matrix(true_labels, pred_labels, labels=unique_labels)
    
    # ç»„ç»‡ç»“æœ
    results = {
        "individual_predictions": [
            {
                "image_path": path,
                "true_label": true,
                "predicted_label": pred,
                "probabilities": prob
            }
            for path, true, pred, prob in zip(image_paths, true_labels, pred_labels, probabilities)
        ],
        "classification_report": report,
        "confusion_matrix": cm.tolist(),
        "confusion_matrix_labels": unique_labels
    }
    
    return results

def main():
    parser = argparse.ArgumentParser(description='æ¨¡å‹é¢„æµ‹ä¸è¯„ä¼°')
    
    # åŸºæœ¬å‚æ•°
    parser.add_argument('--data_path', type=str, help='æ•°æ®é›†è·¯å¾„')
    parser.add_argument('--model_path', type=str, required=True, help='æ¨¡å‹è·¯å¾„')
    parser.add_argument('--output_path', type=str, default='results/evaluation_results.json', help='è¾“å‡ºç»“æœè·¯å¾„')
    parser.add_argument('--subset', type=str, default='val', help='æµ‹è¯•å­é›†ç›®å½•(é»˜è®¤ä¸º val)')
    
    # å›¾åƒå¤„ç†å‚æ•°
    parser.add_argument('--img_size', type=int, default=224, help='å›¾åƒå¤§å°')
    parser.add_argument('--batch_size', type=int, default=32, help='æ‰¹å¤„ç†å¤§å°')
    
    # æ¨¡å‹å‚æ•°
    parser.add_argument('--arch', type=str, default='resnet18', help='æ¨¡å‹æ¶æ„ï¼Œç”¨äºé‡å»ºæ¨¡å‹ï¼ˆå¦‚resnet18ã€resnet34ç­‰ï¼‰')
    parser.add_argument('--classes', type=str, help='ç±»åˆ«åˆ—è¡¨ï¼Œç”¨é€—å·åˆ†éš”ï¼ˆä¾‹å¦‚"cat,dog,horse"ï¼‰')
    
    # è®¾å¤‡å‚æ•°
    parser.add_argument('--device', type=str, choices=['cuda', 'cpu'], default=None, 
                       help='è¿è¡Œè®¾å¤‡ã€‚é»˜è®¤è‡ªåŠ¨é€‰æ‹©ï¼Œå¦‚æœæœ‰GPUåˆ™ä½¿ç”¨GPU')

    # æ“ä½œæ¨¡å¼
    mode_group = parser.add_mutually_exclusive_group()
    mode_group.add_argument('--image', type=str, help='è¦é¢„æµ‹çš„å•å¼ å›¾ç‰‡è·¯å¾„')
    
    # åˆ†å‰²ä»»åŠ¡ç›¸å…³
    parser.add_argument('--save_mask', action='store_true', help='ä¿å­˜é¢„æµ‹çš„åˆ†å‰²æ©ç ')
    
    args = parser.parse_args()
    
    # åˆ¤æ–­æ˜¯å¦ä¸ºåˆ†å‰²æ¨¡å‹
    is_segmentation = args.arch.lower().endswith('_seg')
    
    # å¦‚æœæ˜¯åˆ†å‰²ä»»åŠ¡ä¸”æœªæŒ‡å®šimg_sizeï¼Œä½¿ç”¨æ›´å¤§çš„é»˜è®¤å€¼
    if is_segmentation and args.img_size == 320:
        args.img_size = 2048
        print(f"åˆ†å‰²ä»»åŠ¡ï¼Œä½¿ç”¨é»˜è®¤å›¾åƒå°ºå¯¸: {args.img_size}")
    
    # # è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œç”¨äºæ¨¡å‹é‡å»º
    # os.environ['MODEL_ARCH'] = args.arch
    
    # å¦‚æœæä¾›äº†ç±»åˆ«åˆ—è¡¨ï¼Œè§£æå¹¶å­˜å‚¨åœ¨ç¯å¢ƒå˜é‡ä¸­
    if args.classes:
        classes = [c.strip() for c in args.classes.split(',')]
        os.environ['MODEL_CLASSES'] = ','.join(classes)
        print(f"ä½¿ç”¨æŒ‡å®šçš„ç±»åˆ«åˆ—è¡¨: {classes}")
    
    # è®¾ç½®è®¾å¤‡
    if args.device == 'cuda' and not torch.cuda.is_available():
        print("è­¦å‘Šï¼šCUDAä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPU")
        args.device = 'cpu'
    
    # åˆ¤æ–­æ¨¡å‹ç±»å‹
    is_onnx_model = 'onnx' in args.model_path.lower()
    
    # å•å¼ å›¾ç‰‡é¢„æµ‹
    if args.image:
        if is_onnx_model:
            if is_segmentation:
                predict_single_image_onnx_seg(
                    model_path=args.model_path,
                    image_path=args.image,
                    device=args.device,
                    img_size=args.img_size
                )
            else:
                predict_single_image_onnx(
                    model_path=args.model_path,
                    image_path=args.image,
                    device=args.device,
                    img_size=args.img_size,
                    classes=args.classes,
                    data_path=args.data_path
                )
        else:
            predict_single_image(
                model_path=args.model_path,
                image_path=args.image,
                arch=args.arch,
                device=args.device,
                img_size=args.img_size,
                classes=args.classes,
                data_path=args.data_path,
                save_mask=args.save_mask
            )
        return
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šæ“ä½œæ¨¡å¼ï¼Œæ‰§è¡Œæ•°æ®é›†è¯„ä¼°
    if not args.data_path:
        print("é”™è¯¯ï¼šæœªæŒ‡å®šæ•°æ®é›†è·¯å¾„ã€‚è¯·ä½¿ç”¨ --data_path æŒ‡å®šæ•°æ®é›†è·¯å¾„ï¼Œæˆ–ä½¿ç”¨ --image è¿›è¡Œå•å¼ å›¾ç‰‡é¢„æµ‹ã€‚")
        return
    
    # åˆ†å‰²ä»»åŠ¡çš„æ•°æ®é›†è¯„ä¼°
    if is_segmentation:
        print("å¼€å§‹è¯„ä¼°åˆ†å‰²æ¨¡å‹...")
        try:
            learn = load_model(args.model_path, args.arch, args.device, args.data_path, args.img_size)
            print(f"åˆ†å‰²æ¨¡å‹åŠ è½½æˆåŠŸ")
            
            # è¯„ä¼°åˆ†å‰²æ¨¡å‹
            output_dir = Path(args.output_path).parent
            results = evaluate_segmentation_model(learn, args.data_path, args.img_size, output_dir)
            
            # ä¿å­˜ç»“æœ
            save_results(results, args.output_path, is_segmentation=True)
        except Exception as e:
            print(f"åˆ†å‰²æ¨¡å‹è¯„ä¼°å¤±è´¥ï¼š{e}")
            import traceback
            traceback.print_exc()
            return
    
    else:
        # åˆ†ç±»ä»»åŠ¡çš„æ•°æ®é›†è¯„ä¼°
        # æ„å»ºæµ‹è¯•æ•°æ®é›†
        test_df, data_path = build_test_df(args.data_path, args.subset)
        print(f"æ‰¾åˆ° {len(test_df)} å¼ æµ‹è¯•å›¾ç‰‡")
        
        if len(test_df) == 0:
            print(f"é”™è¯¯ï¼šåœ¨ {args.data_path}/{args.subset} ç›®å½•ä¸‹æœªæ‰¾åˆ°å›¾ç‰‡")
            return
        
        # å¦‚æœæ²¡æœ‰æŒ‡å®šç±»åˆ«ï¼Œä»æµ‹è¯•æ•°æ®é›†ä¸­è·å–
        if not args.classes and 'MODEL_CLASSES' not in os.environ:
            detected_classes = test_df['label'].unique().tolist()
            if len(detected_classes) > 0:
                os.environ['MODEL_CLASSES'] = ','.join(detected_classes)
                print(f"ä»æµ‹è¯•æ•°æ®é›†æ£€æµ‹åˆ°çš„ç±»åˆ«: {detected_classes}")
        
        # æ ¹æ®æ¨¡å‹ç±»å‹è¿›è¡Œè¯„ä¼°
        if is_onnx_model:
            # ä½¿ç”¨ONNXæ¨¡å‹è¯„ä¼°
            print("ä½¿ç”¨ONNXæ¨¡å‹è¿›è¡Œè¯„ä¼°...")
            results = evaluate_model_onnx(
                model_path=args.model_path, 
                test_df=test_df, 
                data_path=data_path, 
                device=args.device, 
                img_size=args.img_size, 
                classes=args.classes
            )
        else:
            # ä½¿ç”¨PyTorchæ¨¡å‹è¯„ä¼°
            try:
                learn = load_model(args.model_path, args.arch, args.device, args.data_path, args.img_size)
                print(f"æ¨¡å‹åŠ è½½æˆåŠŸï¼Œç±»åˆ«ï¼š{learn.dls.vocab}")
                
                # è¯„ä¼°æ¨¡å‹
                print("å¼€å§‹è¯„ä¼°æ¨¡å‹...")
                results = evaluate_model(learn, test_df, data_path)
            except Exception as e:
                print(f"æ— æ³•åŠ è½½æ¨¡å‹ï¼š{e}")
                import traceback
                traceback.print_exc()
                return
        
        # ä¿å­˜ç»“æœ
        save_results(results, args.output_path, is_segmentation=False)

if __name__ == '__main__':
    main() 
