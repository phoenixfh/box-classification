"""
è®­ç»ƒå›è°ƒå‡½æ•°

åŒ…å«å­¦ä¹ ç‡è°ƒåº¦ã€æ—©åœã€æ¨¡å‹ä¿å­˜ç­‰è®­ç»ƒå›è°ƒã€‚
"""

import os
import math
import numpy as np
import torch
import mlflow
from pathlib import Path
from fastai.callback.core import Callback, CancelFitException
from fastai.callback.tracker import TrackerCallback, Recorder

from .data_loading import is_main_process


class YOLOv11LRScheduler(Callback):
    """
    æ”¹è¿›çš„å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼š
    - çƒ­èº«é˜¶æ®µï¼šçº¿æ€§å¢åŠ 
    - ä½™å¼¦é€€ç«ï¼šä¿æŒè¾ƒé«˜çš„æœ€ç»ˆå­¦ä¹ ç‡ï¼ˆlrfå»ºè®®0.1-0.2ï¼‰
    - æ”¯æŒæœ€å°å­¦ä¹ ç‡é™åˆ¶ï¼Œé¿å…åæœŸå­¦ä¹ ç‡è¿‡å°
    """
    def __init__(self, epochs=100, lr0=0.01, lrf=0.1, warmup_epochs=3, warmup_momentum=0.8, 
                 resume_from_epoch=0, min_lr=None, scheduler_type='cosine'):
        self.lr0 = lr0
        self.lrf = lrf
        self.warmup_epochs = warmup_epochs
        self.warmup_momentum = warmup_momentum
        self.final_lr = lr0 * lrf
        self.total_epochs = epochs + resume_from_epoch
        self.resume_from_epoch = resume_from_epoch
        self.scheduler_type = scheduler_type  # 'cosine', 'cosine_restarts', 'step'
        
        # è®¾ç½®æœ€å°å­¦ä¹ ç‡ï¼ˆé»˜è®¤ä¸ºåˆå§‹å­¦ä¹ ç‡çš„1%ï¼‰
        self.min_lr = min_lr if min_lr is not None else lr0 * 0.01
        # ç¡®ä¿final_lrä¸ä½äºmin_lr
        self.final_lr = max(self.final_lr, self.min_lr)
        
    def before_fit(self):
        self.optimizer = self.learn.opt
        
    def before_epoch(self):
        current_epoch = self.learn.epoch + self.resume_from_epoch
        
        # çƒ­èº«é˜¶æ®µ
        if current_epoch < self.warmup_epochs:
            lr = self.lr0 * (0.1 + 0.9 * (current_epoch / self.warmup_epochs))
            momentum = 0.9 - (0.9 - 0.85) * (1 - current_epoch / self.warmup_epochs)
        else:
            # ä¸»è®­ç»ƒé˜¶æ®µï¼šæ ¹æ®scheduler_typeé€‰æ‹©ä¸åŒçš„è°ƒåº¦ç­–ç•¥
            progress = (current_epoch - self.warmup_epochs) / (self.total_epochs - self.warmup_epochs)
            
            if self.scheduler_type == 'cosine':
                # æ ‡å‡†ä½™å¼¦é€€ç«ï¼ˆæ”¹è¿›ï¼šæ›´é«˜çš„æœ€ç»ˆå­¦ä¹ ç‡ï¼‰
                lr = self.final_lr + 0.5 * (self.lr0 - self.final_lr) * (1 + math.cos(math.pi * progress))
                
            elif self.scheduler_type == 'cosine_restarts':
                # ä½™å¼¦é€€ç« + å‘¨æœŸæ€§é‡å¯ï¼ˆæ¯1/3å‘¨æœŸé‡å¯ä¸€æ¬¡ï¼‰
                restart_period = (self.total_epochs - self.warmup_epochs) / 3
                cycle_progress = (current_epoch - self.warmup_epochs) % restart_period / restart_period
                lr = self.final_lr + 0.5 * (self.lr0 - self.final_lr) * (1 + math.cos(math.pi * cycle_progress))
                
            elif self.scheduler_type == 'step':
                # åˆ†æ®µä½™å¼¦è¡°å‡ï¼šå‰70%ä½™å¼¦è¡°å‡ï¼Œå30%ä¿æŒè¾ƒé«˜å­¦ä¹ ç‡
                if progress < 0.7:
                    # å‰70%ä½¿ç”¨ä½™å¼¦è¡°å‡åˆ°final_lr
                    local_progress = progress / 0.7
                    lr = self.final_lr + 0.5 * (self.lr0 - self.final_lr) * (1 + math.cos(math.pi * local_progress))
                else:
                    # å30%ä¿æŒfinal_lrï¼ˆæ¯”æ ‡å‡†ä½™å¼¦é€€ç«é«˜ï¼‰
                    lr = self.final_lr
            else:
                # é»˜è®¤ä½¿ç”¨æ ‡å‡†ä½™å¼¦é€€ç«
                lr = self.final_lr + 0.5 * (self.lr0 - self.final_lr) * (1 + math.cos(math.pi * progress))
            
            # åº”ç”¨æœ€å°å­¦ä¹ ç‡é™åˆ¶
            lr = max(lr, self.min_lr)
            momentum = 0.9
        
        # ä½¿ç”¨ fastai çš„ set_hypers æ–¹æ³•æ›´æ–°å­¦ä¹ ç‡å’ŒåŠ¨é‡
        self.optimizer.set_hypers(lr=lr, mom=momentum)


class LoadOptimizerStateCallback(Callback):
    """åœ¨è®­ç»ƒå¼€å§‹å‰åŠ è½½ä¼˜åŒ–å™¨çŠ¶æ€"""
    def __init__(self, optimizer_state, override_hypers=None):
        """
        Args:
            optimizer_state: è¦åŠ è½½çš„ä¼˜åŒ–å™¨çŠ¶æ€å­—å…¸
            override_hypers: å¯é€‰ï¼Œè¦†ç›–æ¢å¤çš„è¶…å‚æ•°çš„å­—å…¸
                            ä¾‹å¦‚: {'wd': 0.001, 'lr': 0.01}
        """
        self.optimizer_state = optimizer_state
        self.override_hypers = override_hypers or {}
        self.loaded = False
    
    def before_fit(self):
        """åœ¨fitå¼€å§‹å‰å°è¯•åŠ è½½ä¼˜åŒ–å™¨çŠ¶æ€"""
        if not self.loaded and self.optimizer_state is not None:
            # æ­¤æ—¶ä¼˜åŒ–å™¨å¯èƒ½è¿˜æœªåˆå§‹åŒ–ï¼Œå…ˆç­‰å¾…
            pass
    
    def before_train(self):
        """åœ¨è®­ç»ƒå¾ªç¯å¼€å§‹å‰åŠ è½½ä¼˜åŒ–å™¨çŠ¶æ€ï¼ˆæ­¤æ—¶ä¼˜åŒ–å™¨å·²åˆå§‹åŒ–ï¼‰"""
        if not self.loaded and self.optimizer_state is not None:
            try:
                # ç¡®ä¿ä¼˜åŒ–å™¨å·²ç»åˆå§‹åŒ–
                if self.learn.opt is None:
                    print("âš ï¸  ä¼˜åŒ–å™¨å°šæœªåˆå§‹åŒ–ï¼Œç­‰å¾…ä¸‹ä¸€æ¬¡å°è¯•...")
                    return
                
                # è·å–æ¨¡å‹æ‰€åœ¨çš„è®¾å¤‡
                device = next(self.learn.model.parameters()).device
                
                # å°†ä¼˜åŒ–å™¨çŠ¶æ€ç§»åŠ¨åˆ°æ­£ç¡®çš„è®¾å¤‡
                optimizer_state_on_device = self._move_optimizer_state_to_device(
                    self.optimizer_state, device
                )
                
                # åŠ è½½ä¼˜åŒ–å™¨çŠ¶æ€
                self.learn.opt.load_state_dict(optimizer_state_on_device)
                
                # å¦‚æœæœ‰è¦†ç›–çš„è¶…å‚æ•°ï¼Œåº”ç”¨å®ƒä»¬
                if self.override_hypers:
                    if is_main_process():
                        print(f"\nğŸ”§ è¦†ç›–ä¼˜åŒ–å™¨è¶…å‚æ•°:")
                        for key, value in self.override_hypers.items():
                            print(f"   {key}: {value}")
                    
                    # æ›´æ–°æ‰€æœ‰å‚æ•°ç»„çš„è¶…å‚æ•°
                    for param_group in self.learn.opt.param_groups:
                        for key, value in self.override_hypers.items():
                            param_group[key] = value
                
                # è¾“å‡ºæ¢å¤çš„ä¼˜åŒ–å™¨å‚æ•°ä»¥ä¾¿éªŒè¯
                self._print_optimizer_params()
                self.loaded = True
            except Exception as e:
                print(f"âš ï¸  è­¦å‘Š: æ— æ³•åŠ è½½ä¼˜åŒ–å™¨çŠ¶æ€: {e}")
                print("   å°†ä½¿ç”¨æ–°çš„ä¼˜åŒ–å™¨çŠ¶æ€ç»§ç»­è®­ç»ƒ")
                import traceback
                traceback.print_exc()
                self.loaded = True  # æ ‡è®°ä¸ºå·²å°è¯•ï¼Œé¿å…é‡å¤å°è¯•
    
    def _move_optimizer_state_to_device(self, state_dict, device):
        """å°†ä¼˜åŒ–å™¨çŠ¶æ€å­—å…¸ä¸­çš„æ‰€æœ‰å¼ é‡ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡"""
        import torch
        
        def move_to_device(obj):
            """é€’å½’åœ°å°†å¼ é‡ç§»åŠ¨åˆ°ç›®æ ‡è®¾å¤‡"""
            if isinstance(obj, torch.Tensor):
                return obj.to(device)
            elif isinstance(obj, dict):
                return {key: move_to_device(value) for key, value in obj.items()}
            elif isinstance(obj, list):
                return [move_to_device(item) for item in obj]
            elif isinstance(obj, tuple):
                return tuple(move_to_device(item) for item in obj)
            else:
                return obj
        
        return move_to_device(state_dict)
    
    def _print_optimizer_params(self):
        """æ‰“å°ä¼˜åŒ–å™¨å‚æ•°ä»¥ä¾¿éªŒè¯"""
        if is_main_process():
            print("âœ… ä¼˜åŒ–å™¨çŠ¶æ€å·²æ¢å¤ï¼ˆè®­ç»ƒå¼€å§‹å‰ï¼‰")
            try:
                # æ˜¾ç¤ºå‚æ•°ç»„æ•°é‡
                print(f"ğŸ“Š æ¢å¤çš„ä¼˜åŒ–å™¨å‚æ•°:")
                print(f"   - å‚æ•°ç»„æ•°é‡: {len(self.learn.opt.param_groups)}")
                
                # æ˜¾ç¤ºæ¯ä¸ªå‚æ•°ç»„çš„è¯¦ç»†ä¿¡æ¯
                for i, pg in enumerate(self.learn.opt.param_groups):
                    print(f"\n   ç»„ {i}:")
                    print(f"     - lr: {pg.get('lr', 'N/A')}")
                    
                    # FastAI ä½¿ç”¨ 'mom' å’Œ 'wd'ï¼Œè€Œä¸æ˜¯ 'momentum' å’Œ 'weight_decay'
                    momentum = pg.get('mom', pg.get('momentum', 'N/A'))
                    weight_decay = pg.get('wd', pg.get('weight_decay', 'N/A'))
                    
                    print(f"     - mom: {momentum}")
                    print(f"     - wd: {weight_decay}")
                    print(f"     - å‚æ•°æ•°é‡: {len(pg['params'])}")
                
                # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰ç»„çš„ wd ä¸€è‡´
                wd_values = []
                for pg in self.learn.opt.param_groups:
                    wd = pg.get('wd', pg.get('weight_decay', None))
                    if wd is not None:
                        wd_values.append(wd)
                
                if len(set(wd_values)) > 1:
                    print(f"\n   âš ï¸  æ³¨æ„: ä¸åŒå‚æ•°ç»„ä½¿ç”¨ä¸åŒçš„æƒé‡è¡°å‡å€¼")
                    print(f"       å€¼: {set(wd_values)}")
                
            except Exception as e:
                print(f"   æ— æ³•æ˜¾ç¤ºä¼˜åŒ–å™¨å‚æ•°: {e}")


class ResumeEpochCallback(Callback):
    """ä¿®æ­£ä»checkpointæ¢å¤æ—¶çš„epochæ˜¾ç¤º"""
    def __init__(self, resume_from_epoch=0):
        self.resume_from_epoch = resume_from_epoch
    
    def after_epoch(self):
        """åœ¨æ˜¾ç¤ºmetricsæ—¶ä¿®æ­£epochæ•°å€¼"""
        if self.resume_from_epoch > 0 and is_main_process():
            actual_epoch = self.learn.epoch + self.resume_from_epoch
            # åœ¨ç»ˆç«¯è¾“å‡ºå®é™…çš„ epoch ä¿¡æ¯
            print(f"  (å®é™…å®Œæˆçš„ epoch: {actual_epoch})")


class EarlyStoppingWithEvalCallback(TrackerCallback):
    """æ—©åœå›è°ƒï¼Œè§¦å‘æ—¶è¿›è¡Œæ¨¡å‹è¯„ä¼°"""
    def __init__(self, monitor='valid_loss', patience=5, resume_best_metric=None):
        super().__init__(monitor=monitor)
        self.patience = patience
        self.wait = 0
        self.triggered = False  # æ ‡è®°æ˜¯å¦è§¦å‘äº†æ—©åœ
        self.resume_best_metric = resume_best_metric  # æ¢å¤çš„æœ€ä½³æŒ‡æ ‡
    
    def before_fit(self):
        """åœ¨è®­ç»ƒå¼€å§‹å‰ï¼Œå¦‚æœæœ‰æ¢å¤çš„ best_metricï¼Œä½¿ç”¨å®ƒ"""
        super().before_fit()
        if self.resume_best_metric is not None:
            self.best = self.resume_best_metric
            if is_main_process():
                print(f"âœ… æ—©åœå›è°ƒæ¢å¤æœ€ä½³æŒ‡æ ‡: {self.best:.4f}")
        
    def after_epoch(self):
        super().after_epoch()  # çˆ¶ç±»ä¼šè®¾ç½® self.best å’Œ self.new_best
        
        # ä½¿ç”¨çˆ¶ç±»çš„ new_best å±æ€§åˆ¤æ–­æ˜¯å¦æœ‰æ”¹å–„
        if self.new_best:
            # æœ‰æ”¹å–„ï¼Œé‡ç½®ç­‰å¾…è®¡æ•°
            self.wait = 0
            if is_main_process():
                print(f"ğŸ“‰ {self.monitor} æ”¹å–„: {self.best:.4f} (é‡ç½®æ—©åœè®¡æ•°)")
        else:
            # æ— æ”¹å–„ï¼Œå¢åŠ ç­‰å¾…è®¡æ•°
            self.wait += 1

            if self.wait >= self.patience:
                if is_main_process():
                    print(f'\nâš ï¸  æ—©åœè§¦å‘: {self.monitor} åœ¨ {self.patience} ä¸ª epoch å†…æ²¡æœ‰æ”¹å–„, æœ€ä½³ {self.monitor}: {self.best:.4f}')
                self.triggered = True
                raise CancelFitException()


class SaveModelWithEpochCallback(TrackerCallback):
    """ä¿å­˜æ¨¡å‹æ—¶åŒæ—¶ä¿å­˜å½“å‰epochä¿¡æ¯ã€img_sizeå’Œarchï¼Œå¹¶åœ¨æ¯ä¸ªepochåä¿å­˜last.pth """
    
    def __init__(self, monitor='valid_loss', fname='best', last_fname='last', with_opt=True, 
                 resume_from_epoch=0, img_size=None, arch=None, resume_best_metric=None, 
                 save_dir=None, save_last=True, upload_to_mlflow=False):
        # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–ï¼Œå¤„ç† monitor å’Œ compï¼ˆvalid_loss è¶Šå°è¶Šå¥½ï¼‰
        super().__init__(monitor=monitor, comp=np.less)
        
        # è‡ªå®šä¹‰å‚æ•°
        self.fname = fname
        self.last_fname = last_fname
        self.with_opt = with_opt
        self.resume_from_epoch = resume_from_epoch
        self.img_size = img_size
        self.arch = arch
        self.save_dir = save_dir
        self.save_last = save_last
        self.upload_to_mlflow = upload_to_mlflow
        
        # å¦‚æœæœ‰æ¢å¤çš„æœ€ä½³æŒ‡æ ‡ï¼Œè®¾ç½®åˆå§‹å€¼ï¼ˆTrackerCallback ä½¿ç”¨ self.bestï¼‰
        if resume_best_metric is not None:
            self.best = resume_best_metric
    
    def _save_model(self, fname, actual_epoch, current_metric=None):
        """ç»Ÿä¸€çš„æ¨¡å‹ä¿å­˜é€»è¾‘"""
        # ç¡®å®šä¿å­˜è·¯å¾„
        if self.save_dir is not None:
            model_path = Path(self.save_dir) / f'{fname}.pth'
        else:
            model_path = self.learn.path / self.learn.model_dir / f'{fname}.pth'
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        model_path.parent.mkdir(parents=True, exist_ok=True)
        
        # è·å–æ¨¡å‹çŠ¶æ€ï¼ˆå¤„ç†DDPåŒ…è£…ï¼‰
        if hasattr(self.learn.model, 'module'):
            model_state = self.learn.model.module.state_dict()
        else:
            model_state = self.learn.model.state_dict()
        
        # æ„å»ºä¿å­˜çš„çŠ¶æ€å­—å…¸
        state = {
            'model': model_state,
            'epoch': actual_epoch,
            'img_size': self.img_size,
            'arch': self.arch,
            "loss": current_metric,
        }
        
        if self.with_opt:
            # æ£€æŸ¥ä¼˜åŒ–å™¨æ˜¯å¦å­˜åœ¨
            if not hasattr(self.learn, 'opt') or self.learn.opt is None:
                if is_main_process():
                    print("âš ï¸  ä¼˜åŒ–å™¨è¿˜æœªåˆå§‹åŒ–ï¼Œè·³è¿‡ä¿å­˜ä¼˜åŒ–å™¨çŠ¶æ€")
            else:
                state['opt'] = self.learn.opt.state_dict()
                
                # # è¾“å‡ºä¿å­˜çš„ä¼˜åŒ–å™¨å‚æ•°
                # if is_main_process():
                #     self._print_save_optimizer_params(state['opt'])
        
        # ä¿å­˜
        torch.save(state, model_path)
        return model_path, current_metric
    
    def _print_save_optimizer_params(self, opt_state):
        """æ‰“å°è¦ä¿å­˜çš„ä¼˜åŒ–å™¨å‚æ•°ï¼ˆæ”¯æŒ PyTorch å’Œ FastAI æ ¼å¼ï¼‰"""
        try:
            # æ£€æŸ¥ä¼˜åŒ–å™¨çŠ¶æ€æ˜¯å¦ä¸ºç©ºæˆ–æ— æ•ˆ
            if not opt_state:
                print("ğŸ’¾ ä¿å­˜ä¼˜åŒ–å™¨çŠ¶æ€: âš ï¸  ä¼˜åŒ–å™¨çŠ¶æ€ä¸ºç©ºï¼ˆå¯èƒ½è®­ç»ƒè¿˜æœªå¼€å§‹ï¼‰")
                return
            
            if not isinstance(opt_state, dict):
                print(f"ğŸ’¾ ä¿å­˜ä¼˜åŒ–å™¨çŠ¶æ€: âš ï¸  ä¼˜åŒ–å™¨çŠ¶æ€ç±»å‹å¼‚å¸¸ ({type(opt_state)})")
                return
            
            print("ğŸ’¾ ä¿å­˜ä¼˜åŒ–å™¨çŠ¶æ€:")
            
            # FastAI ä¼˜åŒ–å™¨æ ¼å¼ï¼šä½¿ç”¨ 'hypers' è€Œä¸æ˜¯ 'param_groups'
            if 'hypers' in opt_state:
                print("   - æ ¼å¼: FastAI (hypers)")
                hypers = opt_state['hypers']
                
                # hypers å¯èƒ½æ˜¯ fastcore.foundation.L ç±»å‹æˆ–æ™®é€šåˆ—è¡¨
                # éƒ½æ”¯æŒ len() å’Œè¿­ä»£
                try:
                    hypers_len = len(hypers)
                    print(f"   - å‚æ•°ç»„æ•°é‡: {hypers_len}")
                    
                    for i, hyper_group in enumerate(hypers):
                        print(f"\n   ç»„ {i}:")
                        
                        # FastAI hypers æ˜¯å­—å…¸çš„å­—å…¸ï¼š{param_name: {hyper_name: value}}
                        if isinstance(hyper_group, dict):
                            print(f"     - å‚æ•°æ•°é‡: {len(hyper_group)}")
                            
                            # æ‰“å°å‰å‡ ä¸ªå‚æ•°çš„è¯¦ç»†ä¿¡æ¯ç”¨äºè°ƒè¯•
                            print(f"     - å‚æ•°ç¤ºä¾‹:")
                            for idx, (param_idx, param_hypers) in enumerate(list(hyper_group.items())):
                                print(f"       [{param_idx}]: {param_hypers}")
                            
                        else:
                            print(f"     âš ï¸  ä¸æ˜¯å­—å…¸ç±»å‹")
                except Exception as e:
                    print(f"   âš ï¸  è§£æ hypers å¤±è´¥: {e}")
                    print(f"   hypers ç±»å‹: {type(hypers)}")
                
                # æ˜¾ç¤º state ä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                if 'state' in opt_state:
                    state = opt_state['state']
                    if isinstance(state, dict):
                        state_size = len(state)
                    elif hasattr(state, '__len__'):
                        state_size = len(state)
                    else:
                        state_size = f"æœªçŸ¥ç±»å‹ ({type(state).__name__})"
                    print(f"\n   - state å¤§å°: {state_size}")
                
                return
            
            # PyTorch æ ‡å‡†ä¼˜åŒ–å™¨æ ¼å¼ï¼šä½¿ç”¨ 'param_groups'
            if 'param_groups' not in opt_state:
                print(f"   âš ï¸  æœªçŸ¥çš„ä¼˜åŒ–å™¨æ ¼å¼")
                print(f"   å®é™…çš„é”®: {list(opt_state.keys())}")
                return
            
            print("   - æ ¼å¼: PyTorch (param_groups)")
            print(f"   - å‚æ•°ç»„æ•°é‡: {len(opt_state['param_groups'])}")
            
            # æ˜¾ç¤ºæ¯ä¸ªå‚æ•°ç»„çš„è¯¦ç»†ä¿¡æ¯
            for i, pg in enumerate(opt_state['param_groups']):
                print(f"\n   ç»„ {i}:")
                
                # æ˜¾ç¤ºå…³é”®å‚æ•°
                lr = pg.get('lr', 'N/A')
                wd = pg.get('wd', 'N/A')
                weight_decay = pg.get('weight_decay', 'N/A')
                mom = pg.get('mom', pg.get('momentum', 'N/A'))
                
                print(f"     - lr: {lr}")
                print(f"     - mom: {mom}")
                print(f"     - wd: {wd}")
                print(f"     - weight_decay: {weight_decay}")
                print(f"     - å‚æ•°æ•°é‡:                 {len(pg.get('params', []))}")
                
                # æ˜¾ç¤ºæ‰€æœ‰é”®ï¼ˆç”¨äºè°ƒè¯•ï¼‰
                if i == 0:  # åªæ˜¾ç¤ºç¬¬ä¸€ä¸ªç»„çš„æ‰€æœ‰é”®
                    other_keys = [k for k in pg.keys() if k not in ['lr', 'wd', 'weight_decay', 'mom', 'momentum', 'params']]
                    if other_keys:
                        print(f"     - å…¶ä»–é”®: {', '.join(other_keys)}")
            
            # è­¦å‘Šï¼šwd å’Œ weight_decay ä¸ä¸€è‡´
            for i, pg in enumerate(opt_state['param_groups']):
                wd = pg.get('wd', None)
                weight_decay = pg.get('weight_decay', None)
                
                if wd is not None and weight_decay is not None:
                    if abs(float(wd) - float(weight_decay)) > 1e-6:
                        print(f"\n   âš ï¸  ç»„ {i}: wd ({wd}) å’Œ weight_decay ({weight_decay}) ä¸ä¸€è‡´")
            
        except Exception as e:
            print(f"   æ— æ³•æ˜¾ç¤ºä¼˜åŒ–å™¨å‚æ•°: {e}")
    
    def _upload_to_mlflow(self, model_path):
        """ä¸Šä¼ æ¨¡å‹åˆ° MLflowï¼ˆå¸¦ç­¾åå’Œç¤ºä¾‹ï¼‰"""
        try:
            from mlflow.models.signature import infer_signature

            # è·å–åŸå§‹æ¨¡å‹ï¼ˆå»é™¤ DDP åŒ…è£…ï¼‰
            if hasattr(self.learn.model, 'module'):
                model_to_log = self.learn.model.module
            else:
                model_to_log = self.learn.model
            
            # åˆ›å»ºéšæœºç¤ºä¾‹è¾“å…¥ï¼ˆæœ€å®‰å…¨çš„æ–¹å¼ï¼Œé¿å…ä»»ä½•DataLoaderå‰¯ä½œç”¨ï¼‰
            # å½¢çŠ¶: [batch_size, channels, height, width]
            # éœ€è¦ä¸æ¨¡å‹åœ¨åŒä¸€è®¾å¤‡ä¸Š
            device = next(model_to_log.parameters()).device
            input_example = torch.randn(1, 3, self.img_size, self.img_size, device=device)

            # temp_dl. 
            # è¿è¡Œä¸€æ¬¡å‰å‘ä¼ æ’­è·å–è¾“å‡º
            with torch.no_grad():
                output = model_to_log(input_example)
            
            # æ¨æ–­æ¨¡å‹ç­¾å
            signature = infer_signature(
                input_example.cpu().numpy(),
                output.cpu().numpy()
            )
            
            # ä½¿ç”¨ mlflow.pytorch.log_model ä¸Šä¼  PyTorch æ¨¡å‹ï¼ˆå¸¦ç­¾åå’Œç¤ºä¾‹ï¼‰
            mlflow.pytorch.log_model(
                pytorch_model=model_to_log,
                name="best",
                signature=signature,
                input_example=input_example.cpu().numpy(),
                registered_model_name=None,  # ä¸è‡ªåŠ¨æ³¨å†Œåˆ° Model Registry
            )
            print(f"   ğŸ“¤ å·²ä¸Šä¼  PyTorch æ¨¡å‹åˆ° MLflowï¼ˆåŒ…å«æ¨¡å‹ç­¾åï¼‰")
            
        except Exception as sig_error:
            # å¦‚æœç­¾åæ¨æ–­å¤±è´¥ï¼Œå›é€€åˆ°ä¸å¸¦ç­¾åçš„ä¸Šä¼ 
            print(f"   âš ï¸  æ¨¡å‹ç­¾åæ¨æ–­å¤±è´¥: {sig_error}ï¼Œä½¿ç”¨ä¸å¸¦ç­¾åçš„æ–¹å¼ä¸Šä¼ ")
            mlflow.pytorch.log_model(
                pytorch_model=model_to_log,
                name="best",
                registered_model_name=None
            )
            print(f"   ğŸ“¤ å·²ä¸Šä¼  PyTorch æ¨¡å‹åˆ° MLflow")

    def _get_monitor_value(self):

        # FastAIçš„metric_namesç¬¬ä¸€ä¸ªæ˜¯'epoch'ï¼Œä½†valuesä¸­ä¸åŒ…å«epoch
        # æ‰€ä»¥éœ€è¦ä»metric_names[1:]å¼€å§‹åŒ¹é…
        last_values = self.learn.recorder.values[-1]

        metric_names = self.learn.recorder.metric_names[1:]  # è·³è¿‡ 'epoch'
        
        try:
            metric_idx = metric_names.index(self.monitor)
            return last_values[metric_idx]
        except (ValueError, IndexError) as e:
            # å¦‚æœæ‰¾ä¸åˆ°æŒ‡æ ‡æˆ–ç´¢å¼•è¶…å‡ºèŒƒå›´ï¼Œæ‰“å°è°ƒè¯•ä¿¡æ¯å¹¶è·³è¿‡
            print(f"âš ï¸  æ— æ³•æ‰¾åˆ°ç›‘æ§æŒ‡æ ‡ '{self.monitor}'")
            print(f"   å¯ç”¨æŒ‡æ ‡: {metric_names}")
            print(f"   valuesé•¿åº¦: {len(last_values)}")
            return None
        
    def after_epoch(self):
        """æ¯ä¸ª epoch åä¿å­˜æ¨¡å‹åˆ°æœ¬åœ°"""
        # åªåœ¨ä¸»è¿›ç¨‹æ‰§è¡Œä¿å­˜
        if not is_main_process():
            return

        super().after_epoch()
        
        # æ³¨æ„ï¼šæ˜¾å¼è°ƒç”¨çˆ¶ç±»æ–¹æ³•ï¼Œé¿å… FastAI çš„å±æ€§æŸ¥æ‰¾é—®é¢˜
        current_metric = self._get_monitor_value()
        if current_metric is None:
            print(f"âš ï¸  æ— æ³•è·å–ç›‘æ§æŒ‡æ ‡ '{self.monitor}'ï¼Œè·³è¿‡ä¿å­˜")
            return

        # è®¡ç®—å®é™…çš„epochï¼ˆè€ƒè™‘resumeï¼‰
        actual_epoch = self.learn.epoch + self.resume_from_epoch
        
        # 1. ä¿å­˜ best æ¨¡å‹åˆ°æœ¬åœ°ï¼ˆä½¿ç”¨ TrackerCallback çš„ new_best() åˆ¤æ–­ï¼‰
        if self.new_best:
            model_path, _ = self._save_model(self.fname, actual_epoch, current_metric)
            print(f"âœ… ä¿å­˜æœ€ä½³æ¨¡å‹åˆ°æœ¬åœ°: {self.fname}.pth, Epoch: {actual_epoch}, {self.monitor}: {current_metric:.4f}")
            
            # ğŸ†• ç«‹å³ä¸ŠæŠ¥æ‰€æœ‰bestæŒ‡æ ‡åˆ°MLflow
            if self.upload_to_mlflow:
                try:
                    import mlflow
                    if mlflow.active_run():
                        # è·å–å½“å‰epochçš„æ‰€æœ‰æŒ‡æ ‡
                        last_values = self.learn.recorder.values[-1]
                        metric_names = self.learn.recorder.metric_names[1:]  # è·³è¿‡ 'epoch'
                        
                        # æ„å»ºbestæŒ‡æ ‡å­—å…¸
                        best_metrics = {'best/epoch': int(actual_epoch)}
                        
                        # éå†æ‰€æœ‰æŒ‡æ ‡ï¼Œæ·»åŠ åˆ°bestæŒ‡æ ‡ä¸­
                        for idx, name in enumerate(metric_names):
                            if idx < len(last_values):
                                value = last_values[idx]
                                # ä½¿ç”¨best/å‰ç¼€å‘½å
                                best_metrics[f'best/{name}'] = float(value)
                        
                        # ä¸ŠæŠ¥åˆ°MLflow
                        mlflow.log_metrics(best_metrics)
                        
                        # # æ‰“å°ä¸ŠæŠ¥çš„æŒ‡æ ‡
                        # print(f"   ğŸ“Š å·²ä¸ŠæŠ¥bestæŒ‡æ ‡åˆ°MLflow:")
                        # for key, value in best_metrics.items():
                        #     if key != 'best/epoch':
                        #         print(f"      - {key}: {value:.4f}")
                        #     else:
                        #         print(f"      - {key}: {value}")
                except Exception as e:
                    print(f"   âš ï¸  ä¸ŠæŠ¥bestæŒ‡æ ‡åˆ°MLflowå¤±è´¥: {e}")
        
        # 2. å§‹ç»ˆä¿å­˜ last æ¨¡å‹ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.save_last:
            self._save_model(self.last_fname, actual_epoch, current_metric)
    
    def after_fit(self):
        """è®­ç»ƒç»“æŸåä¸Šä¼ æœ€ç»ˆçš„ best æ¨¡å‹åˆ° MLflow"""
        if not is_main_process() or not self.upload_to_mlflow:
            return
        
        # ç¡®å®š best æ¨¡å‹è·¯å¾„
        if self.save_dir is not None:
            best_path = Path(self.save_dir) / f'{self.fname}.pth'
        else:
            best_path = self.learn.path / self.learn.model_dir / f'{self.fname}.pth'
        
        # ä¸Šä¼ æœ€ç»ˆçš„ best æ¨¡å‹
        if best_path.exists():
            print(f"\nğŸ“¤ ä¸Šä¼ æœ€ç»ˆ best æ¨¡å‹åˆ° MLflow...")
            try:
                self._upload_to_mlflow(best_path)
                print(f"âœ… æˆåŠŸä¸Šä¼  best æ¨¡å‹åˆ° MLflow")
            except Exception as e:
                print(f"âš ï¸  ä¸Šä¼ åˆ° MLflow å¤±è´¥: {e}")
        else:
            print(f"âš ï¸  best æ¨¡å‹ä¸å­˜åœ¨ï¼Œè·³è¿‡ä¸Šä¼ : {best_path}")



class DistributedValidationDiagnosticCallback(Callback):
    """
    è¯Šæ–­å¤šGPUåˆ†å¸ƒå¼è®­ç»ƒä¸­çš„éªŒè¯lossè®¡ç®—
    
    ç”¨é€”:
        åœ¨å¤šGPUè®­ç»ƒæ—¶ï¼Œåœ¨batchçº§åˆ«æ”¶é›†æ¯ä¸ªGPUçš„åŸå§‹loss
        å¸®åŠ©å‘ç°æ•°æ®åˆ†å¸ƒä¸å‡æˆ–lossèšåˆé—®é¢˜
    
    åŸç†:
        FastAI/Accelerateåœ¨éªŒè¯ç»“æŸæ—¶ä¼šè‡ªåŠ¨gatherå’Œbroadcast lossï¼Œ
        æ‰€ä»¥åœ¨after_epoch()æ—¶æ‰€æœ‰GPUå·²ç»çœ‹åˆ°ç›¸åŒçš„èšåˆåçš„lossã€‚
        
        æœ¬callbackåœ¨after_batch()æ—¶æ”¶é›†æ¯ä¸ªGPUçš„åŸå§‹batch lossï¼Œ
        åœ¨after_epoch()æ—¶æ‰“å°è¯Šæ–­ä¿¡æ¯ï¼ˆæ­¤æ—¶recorderå·²æ›´æ–°ï¼‰ã€‚
    
    ç”¨æ³•:
        callbacks.append(DistributedValidationDiagnosticCallback(verbose=True))
    """
    def __init__(self, verbose=True):
        self.verbose = verbose
        self.epoch_losses = []  # è®°å½•æ¯ä¸ªepochå„GPUçš„å¹³å‡loss
        self.current_epoch_batch_losses = []  # å½“å‰epochéªŒè¯batchçš„lossåˆ—è¡¨
        self.diagnostic_data = None  # ä¿å­˜è¯Šæ–­æ•°æ®ï¼Œåœ¨after_epochæ‰“å°
        
    def before_validate(self):
        """éªŒè¯å¼€å§‹å‰ï¼Œé‡ç½®å½“å‰epochçš„batch losses"""
        self.current_epoch_batch_losses = []
        self.diagnostic_data = None
    
    def after_batch(self):
        """åœ¨æ¯ä¸ªéªŒè¯batchåæ”¶é›†lossï¼ˆå°è¯•åœ¨Accelerateèšåˆä¹‹å‰ï¼‰"""
        if self.training:  # åªåœ¨éªŒè¯é˜¶æ®µæ”¶é›†
            return
        
        try:
            # è·å–å½“å‰batchçš„loss
            if hasattr(self.learn, 'loss') and self.learn.loss is not None:
                batch_loss = float(self.learn.loss.detach().cpu())
                self.current_epoch_batch_losses.append(batch_loss)
        except Exception as e:
            pass  # é™é»˜å¤±è´¥ï¼Œä¸å½±å“è®­ç»ƒ
        
    def after_validate(self):
        """éªŒè¯ç»“æŸåï¼Œæ”¶é›†æ‰€æœ‰GPUçš„batch lossesï¼ˆä½†ä¸æ‰“å°ï¼Œç­‰after_epochï¼‰"""
        try:
            import torch.distributed as dist
            if not dist.is_available() or not dist.is_initialized():
                return
            
            if len(self.current_epoch_batch_losses) == 0:
                return
            
            rank = dist.get_rank()
            world_size = dist.get_world_size()
            
            # è®¡ç®—å½“å‰GPUåœ¨æ‰€æœ‰éªŒè¯batchä¸Šçš„å¹³å‡loss
            local_avg_loss = sum(self.current_epoch_batch_losses) / len(self.current_epoch_batch_losses)
            local_num_batches = len(self.current_epoch_batch_losses)
            
            # æ”¶é›†æ‰€æœ‰GPUçš„å¹³å‡losså’Œbatchæ•°
            all_avg_losses = [torch.zeros(1).cuda() for _ in range(world_size)]
            all_num_batches = [torch.zeros(1).cuda() for _ in range(world_size)]
            
            dist.all_gather(all_avg_losses, torch.tensor([local_avg_loss]).cuda())
            dist.all_gather(all_num_batches, torch.tensor([float(local_num_batches)]).cuda())
            
            # ä¿å­˜æ•°æ®ï¼Œç¨ååœ¨after_epochæ‰“å°
            if rank == 0:
                avg_losses = [t.item() for t in all_avg_losses]
                num_batches = [int(t.item()) for t in all_num_batches]
                
                self.epoch_losses.append(avg_losses)
                
                # è®¡ç®—åŠ æƒå¹³å‡ï¼ˆè€ƒè™‘æ¯ä¸ªGPUå¤„ç†çš„batchæ•°å¯èƒ½ä¸åŒï¼‰
                total_batches = sum(num_batches)
                weighted_avg = sum(l * n for l, n in zip(avg_losses, num_batches)) / total_batches if total_batches > 0 else 0
                simple_avg = sum(avg_losses) / len(avg_losses) if len(avg_losses) > 0 else 0
                
                # ä¿å­˜è¯Šæ–­æ•°æ®
                self.diagnostic_data = {
                    'avg_losses': avg_losses,
                    'num_batches': num_batches,
                    'weighted_avg': weighted_avg,
                    'simple_avg': simple_avg,
                    'std_loss': np.std(avg_losses),
                    'min_loss': min(avg_losses),
                    'max_loss': max(avg_losses),
                    'total_batches': total_batches
                }
                
        except Exception as e:
            if is_main_process() and self.verbose:
                print(f"âš ï¸  åˆ†å¸ƒå¼éªŒè¯è¯Šæ–­æ•°æ®æ”¶é›†å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
    
    def after_epoch(self):
        """åœ¨epochç»“æŸåæ‰“å°è¯Šæ–­ä¿¡æ¯ï¼ˆæ­¤æ—¶recorderå·²æ›´æ–°ä¸ºå½“å‰epochï¼‰"""
        if not is_main_process() or not self.verbose or self.diagnostic_data is None:
            return
        
        try:
            data = self.diagnostic_data
            avg_losses = data['avg_losses']
            num_batches = data['num_batches']
            weighted_avg = data['weighted_avg']
            simple_avg = data['simple_avg']
            std_loss = data['std_loss']
            min_loss = data['min_loss']
            max_loss = data['max_loss']
            total_batches = data['total_batches']
            
            print(f"\n{'='*80}")
            print(f"ğŸ” Epoch {self.learn.epoch} åˆ†å¸ƒå¼éªŒè¯è¯Šæ–­ (Batchçº§åˆ«):")
            print(f"{'='*80}")
            
            # æ‰“å°æ¯ä¸ªGPUçš„ä¿¡æ¯
            print("å„GPUçš„éªŒè¯ä¿¡æ¯:")
            for i, (loss, n_batch) in enumerate(zip(avg_losses, num_batches)):
                marker = ""
                if loss == min_loss:
                    marker = " â† æœ€ä½"
                elif loss == max_loss:
                    marker = " â† æœ€é«˜"
                print(f"  GPU{i}: avg_loss={loss:.6f}, batches={n_batch}{marker}")
            
            print(f"\nç»Ÿè®¡ä¿¡æ¯:")
            print(f"  ç®€å•å¹³å‡: {simple_avg:.6f}")
            print(f"  åŠ æƒå¹³å‡: {weighted_avg:.6f} (è€ƒè™‘batchæ•°)")
            print(f"  æ ‡å‡†å·®: {std_loss:.6f}")
            print(f"  æœ€å°å€¼: {min_loss:.6f}")
            print(f"  æœ€å¤§å€¼: {max_loss:.6f}")
            print(f"  æå·®: {max_loss - min_loss:.6f}")
            print(f"  æ€»batchæ•°: {total_batches}")
            
            # è­¦å‘Šæ£€æŸ¥
            if std_loss > simple_avg * 0.2:
                print(f"\nâš ï¸  è­¦å‘Š: GPUé—´losså·®å¼‚è¾ƒå¤§ (std={std_loss:.6f} > 20%*avg)")
                print(f"   å¯èƒ½åŸå› :")
                print(f"     - éªŒè¯é›†æ•°æ®åˆ†å¸ƒä¸å‡ï¼ˆä¸åŒGPUå¤„ç†ä¸åŒç±»åˆ«ï¼‰")
                print(f"     - æŸäº›ç±»åˆ«ç‰¹åˆ«éš¾ï¼Œå¯¼è‡´å¯¹åº”GPUçš„lossé«˜")
                print(f"   å»ºè®®:")
                print(f"     - æ£€æŸ¥éªŒè¯é›†æ˜¯å¦å·²æ‰“ä¹± (åº”è¯¥çœ‹åˆ° 'ğŸ”€ æ‰“ä¹±éªŒè¯é›†...')")
                print(f"     - æ£€æŸ¥å„GPUå¤„ç†çš„batchæ•°æ˜¯å¦å‡è¡¡")
            elif std_loss > simple_avg * 0.1:
                print(f"\nâš ï¸  æç¤º: GPUé—´lossæœ‰ä¸€å®šå·®å¼‚ (std={std_loss:.6f})")
                print(f"   è¿™åœ¨å¤šGPUè®­ç»ƒä¸­æ˜¯æ­£å¸¸çš„ï¼Œä½†å»ºè®®ç›‘æ§")
            else:
                print(f"\nâœ… GPUé—´lossåˆ†å¸ƒå‡åŒ€ (std={std_loss:.6f} < 10%*avg)")
                print(f"   éªŒè¯é›†æ‰“ä¹±ä¿®å¤å·²ç”Ÿæ•ˆï¼")
            
            # æ£€æŸ¥batchæ•°åˆ†å¸ƒ
            if max(num_batches) - min(num_batches) > 1:
                print(f"\nâš ï¸  æç¤º: GPUé—´batchæ•°ä¸å®Œå…¨å‡è¡¡ (å·®{max(num_batches) - min(num_batches)}ä¸ª)")
                print(f"   è¿™æ˜¯æ­£å¸¸çš„ï¼ˆæ•°æ®æ€»æ•°ä¸èƒ½è¢«GPUæ•°æ•´é™¤ï¼‰")
            
            # å¯¹æ¯”FastAI/AccelerateæŠ¥å‘Šçš„å€¼ï¼ˆç°åœ¨åº”è¯¥æ˜¯å½“å‰epochçš„å€¼ï¼‰
            if hasattr(self.learn.recorder, 'values') and len(self.learn.recorder.values) > 0:
                last_metrics = self.learn.recorder.values[-1]
                if len(last_metrics) >= 2:
                    reported_loss = float(last_metrics[1])
                    print(f"\nå¯¹æ¯”FastAIæŠ¥å‘Š (å½“å‰epoch):")
                    print(f"  FastAIæŠ¥å‘Šçš„valid_loss: {reported_loss:.6f}")
                    print(f"  æˆ‘ä»¬è®¡ç®—çš„åŠ æƒå¹³å‡: {weighted_avg:.6f}")
                    diff = abs(reported_loss - weighted_avg)
                    if diff > 0.01:
                        print(f"  âš ï¸  å·®å¼‚: {diff:.6f}")
                        print(f"     è¯´æ˜: FastAI/Accelerateä½¿ç”¨äº†ä¸åŒçš„èšåˆæ–¹å¼")
                    else:
                        print(f"  âœ… åŸºæœ¬ä¸€è‡´ (å·®å¼‚ < 0.01)")
            
            print(f"{'='*80}\n")
            
        except Exception as e:
            if is_main_process() and self.verbose:
                print(f"âš ï¸  åˆ†å¸ƒå¼éªŒè¯è¯Šæ–­æ‰“å°å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
    
    def after_fit(self):
        """è®­ç»ƒç»“æŸåæ‰“å°æ€»ç»“"""
        if not is_main_process() or not self.verbose or len(self.epoch_losses) == 0:
            return
        
        print(f"\n{'='*80}")
        print(f"ğŸ“Š åˆ†å¸ƒå¼éªŒè¯è¯Šæ–­æ€»ç»“")
        print(f"{'='*80}")
        
        # è®¡ç®—æ•´ä½“ç»Ÿè®¡
        all_epochs_losses = np.array(self.epoch_losses)  # shape: (n_epochs, n_gpus)
        n_epochs, n_gpus = all_epochs_losses.shape
        
        print(f"æ€»å…±è®­ç»ƒ: {n_epochs} epochs, {n_gpus} GPUs")
        
        # æ¯ä¸ªGPUçš„å¹³å‡loss
        print(f"\nå„GPUçš„å¹³å‡valid_loss (æ‰€æœ‰epochs):")
        for gpu_id in range(n_gpus):
            gpu_avg = all_epochs_losses[:, gpu_id].mean()
            gpu_std = all_epochs_losses[:, gpu_id].std()
            print(f"  GPU{gpu_id}: {gpu_avg:.6f} Â± {gpu_std:.6f}")
        
        # æ¯ä¸ªepochçš„GPUé—´å·®å¼‚
        epoch_stds = [np.std(epoch_losses) for epoch_losses in all_epochs_losses]
        avg_std = np.mean(epoch_stds)
        max_std = max(epoch_stds)
        
        print(f"\nGPUé—´losså·®å¼‚:")
        print(f"  å¹³å‡æ ‡å‡†å·®: {avg_std:.6f}")
        print(f"  æœ€å¤§æ ‡å‡†å·®: {max_std:.6f}")
        
        if avg_std > 0.1:
            print(f"\nâš ï¸  è­¦å‘Š: æ•´ä½“GPUé—´å·®å¼‚è¾ƒå¤§")
            print(f"   å»ºè®®:")
            print(f"     - ç¡®è®¤éªŒè¯é›†å·²æ‰“ä¹±")
            print(f"     - æ£€æŸ¥æ•°æ®åŠ è½½æ˜¯å¦æ­£å¸¸")
        else:
            print(f"\nâœ… GPUé—´lossåˆ†å¸ƒæ•´ä½“å‡åŒ€")
            print(f"   éªŒè¯é›†æ‰“ä¹±ä¿®å¤æœ‰æ•ˆï¼")
        
        # è¶‹åŠ¿åˆ†æ
        if n_epochs > 3:
            early_avg_std = np.mean(epoch_stds[:3])
            late_avg_std = np.mean(epoch_stds[-3:])
            print(f"\nè¶‹åŠ¿åˆ†æ:")
            print(f"  å‰3ä¸ªepochå¹³å‡æ ‡å‡†å·®: {early_avg_std:.6f}")
            print(f"  å3ä¸ªepochå¹³å‡æ ‡å‡†å·®: {late_avg_std:.6f}")
            if late_avg_std < early_avg_std * 0.8:
                print(f"  âœ… GPUé—´å·®å¼‚éšè®­ç»ƒå‡å°ï¼ˆæ¨¡å‹å­¦ä¹ å‡è¡¡ï¼‰")
            elif late_avg_std > early_avg_std * 1.2:
                print(f"  âš ï¸  GPUé—´å·®å¼‚éšè®­ç»ƒå¢å¤§ï¼ˆå¯èƒ½è¿‡æ‹Ÿåˆä¸å‡ï¼‰")
            else:
                print(f"  â†’ GPUé—´å·®å¼‚ä¿æŒç¨³å®š")
        
        print(f"{'='*80}\n")
